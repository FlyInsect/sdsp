{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162e4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafeb82",
   "metadata": {},
   "source": [
    "### y label 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95040759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39438\n",
      "2757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39438"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(\"new_label.csv\")\n",
    "print(len(y.loc[y[\"new_label\"] == 0]))\n",
    "print(len(y.loc[y[\"new_label\"] == 1]))\n",
    "y = y[\"new_label\"]\n",
    "#y.head()\n",
    "len(y[y==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22015279",
   "metadata": {},
   "source": [
    "### symptom（，385）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf9ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pediatric Obesity</th>\n",
       "      <th>Orthostatic Intolerance</th>\n",
       "      <th>Seizures</th>\n",
       "      <th>Muscle Weakness</th>\n",
       "      <th>Persistent Vegetative State</th>\n",
       "      <th>Chills</th>\n",
       "      <th>Sweating Sickness</th>\n",
       "      <th>Ataxia</th>\n",
       "      <th>Nocturia</th>\n",
       "      <th>Fetal Distress</th>\n",
       "      <th>...</th>\n",
       "      <th>Hypercalciuria</th>\n",
       "      <th>Chronic Pain</th>\n",
       "      <th>Hematemesis</th>\n",
       "      <th>Angina Pectoris</th>\n",
       "      <th>Vision, Low</th>\n",
       "      <th>Muscle Hypertonia</th>\n",
       "      <th>Hearing Loss, Functional</th>\n",
       "      <th>Breakthrough Pain</th>\n",
       "      <th>Mutism</th>\n",
       "      <th>Cerebrospinal Fluid Otorrhea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actinomycetales infections</th>\n",
       "      <td>1.93364</td>\n",
       "      <td>5.559312</td>\n",
       "      <td>72.041217</td>\n",
       "      <td>60.463165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.653691</td>\n",
       "      <td>3.965454</td>\n",
       "      <td>22.610653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.321535</td>\n",
       "      <td>45.152099</td>\n",
       "      <td>8.997955</td>\n",
       "      <td>11.683219</td>\n",
       "      <td>18.331389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1545</td>\n",
       "      <td>14.206270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adenocarcinoma</th>\n",
       "      <td>5.80092</td>\n",
       "      <td>8.338968</td>\n",
       "      <td>26.247575</td>\n",
       "      <td>36.153233</td>\n",
       "      <td>2.165972</td>\n",
       "      <td>6.826846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.018082</td>\n",
       "      <td>8.108319</td>\n",
       "      <td>1.881661</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433349</td>\n",
       "      <td>11.592921</td>\n",
       "      <td>84.283917</td>\n",
       "      <td>33.742333</td>\n",
       "      <td>14.604023</td>\n",
       "      <td>2.156634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1545</td>\n",
       "      <td>7.103135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Pediatric Obesity  Orthostatic Intolerance  \\\n",
       "actinomycetales infections            1.93364                 5.559312   \n",
       "adenocarcinoma                        5.80092                 8.338968   \n",
       "\n",
       "                             Seizures  Muscle Weakness  \\\n",
       "actinomycetales infections  72.041217        60.463165   \n",
       "adenocarcinoma              26.247575        36.153233   \n",
       "\n",
       "                            Persistent Vegetative State     Chills  \\\n",
       "actinomycetales infections                     0.000000  13.653691   \n",
       "adenocarcinoma                                 2.165972   6.826846   \n",
       "\n",
       "                            Sweating Sickness     Ataxia  Nocturia  \\\n",
       "actinomycetales infections           3.965454  22.610653  0.000000   \n",
       "adenocarcinoma                       0.000000  53.018082  8.108319   \n",
       "\n",
       "                            Fetal Distress  ...  Hypercalciuria  Chronic Pain  \\\n",
       "actinomycetales infections        0.000000  ...        0.000000     19.321535   \n",
       "adenocarcinoma                    1.881661  ...        2.433349     11.592921   \n",
       "\n",
       "                            Hematemesis  Angina Pectoris  Vision, Low  \\\n",
       "actinomycetales infections    45.152099         8.997955    11.683219   \n",
       "adenocarcinoma                84.283917        33.742333    14.604023   \n",
       "\n",
       "                            Muscle Hypertonia  Hearing Loss, Functional  \\\n",
       "actinomycetales infections          18.331389                       0.0   \n",
       "adenocarcinoma                       2.156634                       0.0   \n",
       "\n",
       "                            Breakthrough Pain  Mutism  \\\n",
       "actinomycetales infections                0.0  2.1545   \n",
       "adenocarcinoma                            0.0  2.1545   \n",
       "\n",
       "                            Cerebrospinal Fluid Otorrhea  \n",
       "actinomycetales infections                     14.206270  \n",
       "adenocarcinoma                                  7.103135  \n",
       "\n",
       "[2 rows x 385 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disA_fea_mat = pd.read_csv(\"new_disA_fea_mat.csv\", index_col=0, header=\"infer\")\n",
    "disB_fea_mat = pd.read_csv(\"new_disB_fea_mat.csv\", index_col=0, header=\"infer\")\n",
    "\n",
    "# disA_fea_mat = pd.read_csv(\"concat_mesh_label/con_feaA.csv\",index_col=0,header=\"infer\")\n",
    "# disB_fea_mat = pd.read_csv(\"concat_mesh_label/con_feaB.csv\",index_col=0,header=\"infer\")\n",
    "disB_fea_mat[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488c316",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e111560",
   "metadata": {
    "code_folding": [
     0,
     5,
     9,
     21,
     31,
     39,
     44,
     57,
     75,
     93,
     107,
     139,
     199
    ]
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes           # shape1是batch_size ?\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "class euclLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(euclLayer,self).__init__(name='final_out')\n",
    "        \n",
    "    def __call__(self, x1, x2):\n",
    "        def euclidean_distance(x1,x2):\n",
    "            sum_square = K.sum(K.square(x1-x2), axis=1, keepdims=True)\n",
    "            return  K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "        \n",
    "        value = euclidean_distance(x1,x2)\n",
    "        return value\n",
    "\n",
    "def e_auc(y_true, y_pred):\n",
    "    def euclidean_AUC(y_true,y_pred):\n",
    "        #tf.compat.v1.disable_eager_execution()\n",
    "        #with tf.compat.v1.Session() as sess:\n",
    "            #fpr,tpr,threshold = roc_curve(y_true.eval(),y_pred.eval())\n",
    "        max_pre = np.max(y_pred)\n",
    "        N_y_pred = [(max_pre-i)/max_pre for i in y_pred]\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true,N_y_pred)\n",
    "        return roc_auc\n",
    "\n",
    "    return tf.py_function(euclidean_AUC, (y_true, y_pred),Tout=float)\n",
    "\n",
    "class eucl_AUC(tf.keras.metrics.Metric): \n",
    "    def __init__(self, name='euclidean_AUC', **kwargs):# self.属性是tf.Variable\n",
    "        super(eucl_AUC, self).__init__(name=name, **kwargs)\n",
    "        self.AUC = self.add_weight(name='auc', initializer=tf.zeros_initializer())\n",
    "        self.yt = self.add_weight(name='y_true', initializer=tf.zeros_initializer())\n",
    "        self.yp = self.add_weight(name='y_pred', initializer=tf.zeros_initializer())\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        y_true = tf.concat([self.yt,y_true],axis=0)\n",
    "        y_pred = tf.concat([self.yp,y_pred],axis=0)\n",
    "        \n",
    "        N_y_pred = tf.add(tf.multiply(tf.tanh(y_pred),-1.0),1.0)\n",
    "        \n",
    "        #y_true = tf.reshape(y_true,[-1])\n",
    "        #N_y_pred = tf.reshape(N_y_pred,[-1])\n",
    "        \n",
    "        roc_auc = tf.compat.v1.metrics.auc(self.yt,N_y_pred)\n",
    "        #roc_auc = tf.py_function(func= roc_auc_score,inp=[y_true,N_y_pred],Tout=[tf.float32])\n",
    "        \n",
    "        #roc_auc = tf.convert_to_tensor(roc_auc)\n",
    "        #roc_auc = tf.cast(roc_auc,tf.float32)\n",
    "        #roc_auc = tf.reshape(roc_auc,[1,1])\n",
    "        \n",
    "        self.yt.assign(y_true)\n",
    "        self.yp.assign(y_pred)\n",
    "        self.AUC.assign(roc_auc)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.AUC\n",
    "\n",
    "####################################################################################################################\n",
    "def create_base_network_copy(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).'''\n",
    "    input = Input(shape=input_shape)\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(128)(input))\n",
    "#     x= Activation(activation='relu')(Dense(64)(input))\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(64)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(64)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(32)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "#     x= Activation(activation='relu')(Dense(32)(x))\n",
    "#     x = Dropout(0.1)(x)\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(32)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    x= Activation(activation='sigmoid')(Dense(32)(x))\n",
    "#     x = Dense(32)(x)\n",
    "    \n",
    "    return Model(input, x,name=\"base_net\")\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).'''\n",
    "    input = Input(shape=input_shape)\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(128)(input))\n",
    "#     x= Activation(activation='relu')(Dense(64)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(64)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(32)(x))\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "#     x= Activation(activation='sigmoid')(Dense(32)(x))\n",
    "    x= Activation(activation='sigmoid')(Dense(32)(x))\n",
    "    return Model(input, x,name=\"base_net\")\n",
    "\n",
    "def create_euclLayer(input_shape):\n",
    "    pair1 = Input(shape=(input_shape))\n",
    "    pair2 = Input(shape=(input_shape))\n",
    "              \n",
    "    x = euclLayer()(pair1,pair2)\n",
    "    x = Activation(activation='relu')(x)\n",
    "#     x = Activation(activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=[pair1,pair2],outputs=x,name=\"siamese\")\n",
    "    \n",
    "\"\"\"state-of-the-art：input(64)-64-32-16-1\"\"\"\n",
    "def create_MLP_copy(input_shape):\n",
    "    \n",
    "    input = Input(shape=input_shape)\n",
    "    x= Activation(activation='relu')(Dense(64)(input))\n",
    "#     x= Activation(activation='relu')(Dense(32)(input))\n",
    "    x= Activation(activation='relu')(Dense(32)(x))\n",
    "    x= Activation(activation='relu')(Dense(16)(x))\n",
    "#     x= Activation(activation='relu')(Dense(8)(x))\n",
    "    \n",
    "#     x= Activation(activation='sigmoid',name=\"MLP_out\")(Dense(1)(x))\n",
    "    x= Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(input, x ,name=\"mlp\")\n",
    "\n",
    "def create_MLP(input_shape):\n",
    "    \n",
    "    input = Input(shape=input_shape)\n",
    "    x= Activation(activation='relu')(Dense(64)(input))\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(32)(x))\n",
    "    \n",
    "#     x= Activation(activation='relu')(Dense(32)(x))\n",
    "    x= Activation(activation='relu')(Dense(16)(x))\n",
    "    \n",
    "    x= Activation(activation='relu')(Dense(8)(x))\n",
    "    \n",
    "#     x= Activation(activation='sigmoid',name=\"MLP_out\")(Dense(1)(x))\n",
    "    x= Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(input, x ,name=\"mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e160f",
   "metadata": {},
   "source": [
    "## SDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273ff04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42195, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actinomycetales infections</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adenocarcinoma</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1  2  3  4  5  6  7  8  9  ...  14  15  16  17  \\\n",
       "actinomycetales infections  1  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   \n",
       "adenocarcinoma              0  1  0  0  0  0  0  0  0  0  ...   0   0   0   0   \n",
       "\n",
       "                            18  19  20  21  22  23  \n",
       "actinomycetales infections   0   0   0   0   0   0  \n",
       "adenocarcinoma               0   0   0   0   0   0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_label_A = pd.read_csv(\"concat_mesh_label/mesh_label_A_new.csv\",index_col=0)\n",
    "mesh_label_B = pd.read_csv(\"concat_mesh_label/mesh_label_B_new.csv\",index_col=0)\n",
    "print(mesh_label_B.shape)\n",
    "mesh_label_B[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0052ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mesh_label_A=mesh_label_A.astype(np.float32)\n",
    "mesh_label_B=mesh_label_B.astype(np.float32)\n",
    "\n",
    "y=y.astype(np.float32)\n",
    "\n",
    "\n",
    "y=np.array(y)\n",
    "\n",
    "disA_fea_mat=np.array(disA_fea_mat)\n",
    "disB_fea_mat=np.array(disB_fea_mat)\n",
    "\n",
    "mesh_label_A = np.array(mesh_label_A)\n",
    "mesh_label_B = np.array(mesh_label_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544a066d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rus_y的长度: 5514\n",
      "rus_mesh_B的长度： 5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'PYTHONHASHSEED' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 1 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.3188 - siamese_loss: 1.2517 - mlp_loss: 0.6711 - mlp_binary_accuracy: 0.5941 - mlp_auc_10: 0.6253\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6960 - siamese_loss: 0.6327 - mlp_loss: 0.6328 - mlp_binary_accuracy: 0.6538 - mlp_auc_10: 0.6977\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6488 - siamese_loss: 0.5879 - mlp_loss: 0.6083 - mlp_binary_accuracy: 0.6634 - mlp_auc_10: 0.7301\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5977 - siamese_loss: 0.5395 - mlp_loss: 0.5821 - mlp_binary_accuracy: 0.6943 - mlp_auc_10: 0.7617\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5963 - siamese_loss: 0.5401 - mlp_loss: 0.5621 - mlp_binary_accuracy: 0.7146 - mlp_auc_10: 0.7834\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6256 - siamese_loss: 0.5710 - mlp_loss: 0.5456 - mlp_binary_accuracy: 0.7241 - mlp_auc_10: 0.7977\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6430 - siamese_loss: 0.5901 - mlp_loss: 0.5291 - mlp_binary_accuracy: 0.7426 - mlp_auc_10: 0.8128\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6207 - siamese_loss: 0.5690 - mlp_loss: 0.5172 - mlp_binary_accuracy: 0.7483 - mlp_auc_10: 0.8225\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6003 - siamese_loss: 0.5501 - mlp_loss: 0.5021 - mlp_binary_accuracy: 0.7626 - mlp_auc_10: 0.8347\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5640 - siamese_loss: 0.5141 - mlp_loss: 0.4990 - mlp_binary_accuracy: 0.7642 - mlp_auc_10: 0.8374\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5370 - siamese_loss: 0.4884 - mlp_loss: 0.4862 - mlp_binary_accuracy: 0.7701 - mlp_auc_10: 0.8466\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5200 - siamese_loss: 0.4726 - mlp_loss: 0.4742 - mlp_binary_accuracy: 0.7799 - mlp_auc_10: 0.8554\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5022 - siamese_loss: 0.4550 - mlp_loss: 0.4716 - mlp_binary_accuracy: 0.7862 - mlp_auc_10: 0.8581\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4981 - siamese_loss: 0.4517 - mlp_loss: 0.4639 - mlp_binary_accuracy: 0.7922 - mlp_auc_10: 0.8621\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4810 - siamese_loss: 0.4350 - mlp_loss: 0.4599 - mlp_binary_accuracy: 0.7896 - mlp_auc_10: 0.8648\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6239 - siamese_loss: 0.5762 - mlp_loss: 0.4768 - mlp_binary_accuracy: 0.7769 - mlp_auc_10: 0.8546\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5532 - siamese_loss: 0.5073 - mlp_loss: 0.4591 - mlp_binary_accuracy: 0.7890 - mlp_auc_10: 0.8653\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5433 - siamese_loss: 0.4982 - mlp_loss: 0.4509 - mlp_binary_accuracy: 0.7928 - mlp_auc_10: 0.8697\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.4969 - siamese_loss: 0.4523 - mlp_loss: 0.4457 - mlp_binary_accuracy: 0.7969 - mlp_auc_10: 0.8734\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.4817 - siamese_loss: 0.4380 - mlp_loss: 0.4374 - mlp_binary_accuracy: 0.8025 - mlp_auc_10: 0.8787\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5089 - siamese_loss: 0.4577 - mlp_loss: 0.5123 - mlp_binary_accuracy: 0.7591 - mlp_auc_10: 0.8567\n",
      "------ mlp_binary_accuracy: 75.91%\t ----- mlp_auc_10: 85.67%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 2 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.0652 - siamese_loss: 0.9972 - mlp_loss: 0.6800 - mlp_binary_accuracy: 0.5907 - mlp_auc_11: 0.6132\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6479 - siamese_loss: 0.5836 - mlp_loss: 0.6439 - mlp_binary_accuracy: 0.6487 - mlp_auc_11: 0.6846\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5729 - siamese_loss: 0.5113 - mlp_loss: 0.6157 - mlp_binary_accuracy: 0.6675 - mlp_auc_11: 0.7223\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5247 - siamese_loss: 0.4650 - mlp_loss: 0.5970 - mlp_binary_accuracy: 0.6925 - mlp_auc_11: 0.7462\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5141 - siamese_loss: 0.4555 - mlp_loss: 0.5857 - mlp_binary_accuracy: 0.7048 - mlp_auc_11: 0.7589\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5051 - siamese_loss: 0.4472 - mlp_loss: 0.5788 - mlp_binary_accuracy: 0.7150 - mlp_auc_11: 0.7663\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5376 - siamese_loss: 0.4808 - mlp_loss: 0.5684 - mlp_binary_accuracy: 0.7173 - mlp_auc_11: 0.7775\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5343 - siamese_loss: 0.4786 - mlp_loss: 0.5565 - mlp_binary_accuracy: 0.7277 - mlp_auc_11: 0.7887\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5707 - siamese_loss: 0.5161 - mlp_loss: 0.5460 - mlp_binary_accuracy: 0.7374 - mlp_auc_11: 0.7985\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5325 - siamese_loss: 0.4792 - mlp_loss: 0.5330 - mlp_binary_accuracy: 0.7404 - mlp_auc_11: 0.8103\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4833 - siamese_loss: 0.4313 - mlp_loss: 0.5203 - mlp_binary_accuracy: 0.7515 - mlp_auc_11: 0.8206\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5049 - siamese_loss: 0.4541 - mlp_loss: 0.5077 - mlp_binary_accuracy: 0.7600 - mlp_auc_11: 0.8309\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4890 - siamese_loss: 0.4387 - mlp_loss: 0.5024 - mlp_binary_accuracy: 0.7652 - mlp_auc_11: 0.8345\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4778 - siamese_loss: 0.4288 - mlp_loss: 0.4902 - mlp_binary_accuracy: 0.7727 - mlp_auc_11: 0.8436\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4511 - siamese_loss: 0.4027 - mlp_loss: 0.4833 - mlp_binary_accuracy: 0.7709 - mlp_auc_11: 0.8485\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4668 - siamese_loss: 0.4190 - mlp_loss: 0.4780 - mlp_binary_accuracy: 0.7789 - mlp_auc_11: 0.8523\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4729 - siamese_loss: 0.4259 - mlp_loss: 0.4699 - mlp_binary_accuracy: 0.7864 - mlp_auc_11: 0.8572\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4619 - siamese_loss: 0.4150 - mlp_loss: 0.4696 - mlp_binary_accuracy: 0.7852 - mlp_auc_11: 0.8580\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4527 - siamese_loss: 0.4064 - mlp_loss: 0.4634 - mlp_binary_accuracy: 0.7842 - mlp_auc_11: 0.8620\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4696 - siamese_loss: 0.4238 - mlp_loss: 0.4581 - mlp_binary_accuracy: 0.7908 - mlp_auc_11: 0.8651\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3875 - siamese_loss: 0.3285 - mlp_loss: 0.5903 - mlp_binary_accuracy: 0.7101 - mlp_auc_11: 0.7951\n",
      "------ mlp_binary_accuracy: 71.01%\t ----- mlp_auc_11: 79.51%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 3 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.9670 - siamese_loss: 0.8993 - mlp_loss: 0.6770 - mlp_binary_accuracy: 0.5701 - mlp_auc_12: 0.6046\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5887 - siamese_loss: 0.5249 - mlp_loss: 0.6377 - mlp_binary_accuracy: 0.6429 - mlp_auc_12: 0.6896\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5503 - siamese_loss: 0.4883 - mlp_loss: 0.6199 - mlp_binary_accuracy: 0.6653 - mlp_auc_12: 0.7143\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5464 - siamese_loss: 0.4861 - mlp_loss: 0.6030 - mlp_binary_accuracy: 0.6765 - mlp_auc_12: 0.7387\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5368 - siamese_loss: 0.4782 - mlp_loss: 0.5863 - mlp_binary_accuracy: 0.6951 - mlp_auc_12: 0.7583\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5026 - siamese_loss: 0.4464 - mlp_loss: 0.5626 - mlp_binary_accuracy: 0.7211 - mlp_auc_12: 0.7819\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5310 - siamese_loss: 0.4765 - mlp_loss: 0.5449 - mlp_binary_accuracy: 0.7356 - mlp_auc_12: 0.7994\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5312 - siamese_loss: 0.4776 - mlp_loss: 0.5360 - mlp_binary_accuracy: 0.7384 - mlp_auc_12: 0.8068\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4908 - siamese_loss: 0.4392 - mlp_loss: 0.5161 - mlp_binary_accuracy: 0.7463 - mlp_auc_12: 0.8240\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4910 - siamese_loss: 0.4406 - mlp_loss: 0.5045 - mlp_binary_accuracy: 0.7612 - mlp_auc_12: 0.8329\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4683 - siamese_loss: 0.4190 - mlp_loss: 0.4939 - mlp_binary_accuracy: 0.7624 - mlp_auc_12: 0.8405\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4711 - siamese_loss: 0.4229 - mlp_loss: 0.4821 - mlp_binary_accuracy: 0.7727 - mlp_auc_12: 0.8489\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4567 - siamese_loss: 0.4091 - mlp_loss: 0.4753 - mlp_binary_accuracy: 0.7779 - mlp_auc_12: 0.8536\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4526 - siamese_loss: 0.4060 - mlp_loss: 0.4659 - mlp_binary_accuracy: 0.7864 - mlp_auc_12: 0.8601\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4532 - siamese_loss: 0.4066 - mlp_loss: 0.4657 - mlp_binary_accuracy: 0.7844 - mlp_auc_12: 0.8604\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4487 - siamese_loss: 0.4030 - mlp_loss: 0.4563 - mlp_binary_accuracy: 0.7912 - mlp_auc_12: 0.8650\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4379 - siamese_loss: 0.3933 - mlp_loss: 0.4463 - mlp_binary_accuracy: 0.7922 - mlp_auc_12: 0.8724\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4372 - siamese_loss: 0.3931 - mlp_loss: 0.4411 - mlp_binary_accuracy: 0.7997 - mlp_auc_12: 0.8751\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5456 - siamese_loss: 0.5000 - mlp_loss: 0.4557 - mlp_binary_accuracy: 0.7904 - mlp_auc_12: 0.8667\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4893 - siamese_loss: 0.4448 - mlp_loss: 0.4446 - mlp_binary_accuracy: 0.7954 - mlp_auc_12: 0.8734\n",
      "Epoch 21/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4530 - siamese_loss: 0.4085 - mlp_loss: 0.4445 - mlp_binary_accuracy: 0.7979 - mlp_auc_12: 0.8750\n",
      "Epoch 22/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4429 - siamese_loss: 0.3997 - mlp_loss: 0.4318 - mlp_binary_accuracy: 0.8067 - mlp_auc_12: 0.8808\n",
      "Epoch 23/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4310 - siamese_loss: 0.3877 - mlp_loss: 0.4326 - mlp_binary_accuracy: 0.8015 - mlp_auc_12: 0.8807\n",
      "Epoch 24/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4453 - siamese_loss: 0.4020 - mlp_loss: 0.4334 - mlp_binary_accuracy: 0.8009 - mlp_auc_12: 0.8806\n",
      "Epoch 25/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.4253 - siamese_loss: 0.3829 - mlp_loss: 0.4245 - mlp_binary_accuracy: 0.8059 - mlp_auc_12: 0.8851\n",
      "Epoch 26/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4528 - siamese_loss: 0.4101 - mlp_loss: 0.4267 - mlp_binary_accuracy: 0.8079 - mlp_auc_12: 0.8848\n",
      "Epoch 27/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4393 - siamese_loss: 0.3974 - mlp_loss: 0.4189 - mlp_binary_accuracy: 0.8148 - mlp_auc_12: 0.8895\n",
      "Epoch 28/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4170 - siamese_loss: 0.3757 - mlp_loss: 0.4136 - mlp_binary_accuracy: 0.8136 - mlp_auc_12: 0.8913\n",
      "Epoch 29/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - siamese_loss: 0.3856 - mlp_loss: 0.4181 - mlp_binary_accuracy: 0.8128 - mlp_auc_12: 0.8907\n",
      "Epoch 30/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4244 - siamese_loss: 0.3828 - mlp_loss: 0.4158 - mlp_binary_accuracy: 0.8150 - mlp_auc_12: 0.8903\n",
      "Epoch 31/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4427 - siamese_loss: 0.4015 - mlp_loss: 0.4124 - mlp_binary_accuracy: 0.8192 - mlp_auc_12: 0.8930\n",
      "Epoch 32/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4350 - siamese_loss: 0.3938 - mlp_loss: 0.4118 - mlp_binary_accuracy: 0.8136 - mlp_auc_12: 0.8925\n",
      "Epoch 33/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4412 - siamese_loss: 0.4004 - mlp_loss: 0.4076 - mlp_binary_accuracy: 0.8206 - mlp_auc_12: 0.8948\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - siamese_loss: 0.3948 - mlp_loss: 0.5272 - mlp_binary_accuracy: 0.7446 - mlp_auc_12: 0.8322\n",
      "------ mlp_binary_accuracy: 74.46%\t ----- mlp_auc_12: 83.22%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 4 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.9422 - siamese_loss: 0.8751 - mlp_loss: 0.6708 - mlp_binary_accuracy: 0.5933 - mlp_auc_13: 0.6289\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5892 - siamese_loss: 0.5260 - mlp_loss: 0.6320 - mlp_binary_accuracy: 0.6471 - mlp_auc_13: 0.6999\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5996 - siamese_loss: 0.5387 - mlp_loss: 0.6084 - mlp_binary_accuracy: 0.6745 - mlp_auc_13: 0.7321\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5717 - siamese_loss: 0.5127 - mlp_loss: 0.5894 - mlp_binary_accuracy: 0.6963 - mlp_auc_13: 0.7535\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5199 - siamese_loss: 0.4625 - mlp_loss: 0.5743 - mlp_binary_accuracy: 0.7110 - mlp_auc_13: 0.7697\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5085 - siamese_loss: 0.4531 - mlp_loss: 0.5539 - mlp_binary_accuracy: 0.7281 - mlp_auc_13: 0.7904\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5068 - siamese_loss: 0.4531 - mlp_loss: 0.5368 - mlp_binary_accuracy: 0.7491 - mlp_auc_13: 0.8064\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4845 - siamese_loss: 0.4323 - mlp_loss: 0.5218 - mlp_binary_accuracy: 0.7451 - mlp_auc_13: 0.8188\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5071 - siamese_loss: 0.4560 - mlp_loss: 0.5105 - mlp_binary_accuracy: 0.7549 - mlp_auc_13: 0.8279\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4930 - siamese_loss: 0.4432 - mlp_loss: 0.4988 - mlp_binary_accuracy: 0.7576 - mlp_auc_13: 0.8373\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4801 - siamese_loss: 0.4311 - mlp_loss: 0.4896 - mlp_binary_accuracy: 0.7686 - mlp_auc_13: 0.8443\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5119 - siamese_loss: 0.4633 - mlp_loss: 0.4862 - mlp_binary_accuracy: 0.7701 - mlp_auc_13: 0.8466\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5151 - siamese_loss: 0.4668 - mlp_loss: 0.4832 - mlp_binary_accuracy: 0.7717 - mlp_auc_13: 0.8486\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5287 - siamese_loss: 0.4813 - mlp_loss: 0.4743 - mlp_binary_accuracy: 0.7860 - mlp_auc_13: 0.8554\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5043 - siamese_loss: 0.4573 - mlp_loss: 0.4699 - mlp_binary_accuracy: 0.7785 - mlp_auc_13: 0.8589\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4818 - siamese_loss: 0.4358 - mlp_loss: 0.4604 - mlp_binary_accuracy: 0.7850 - mlp_auc_13: 0.8640\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4221 - siamese_loss: 0.3640 - mlp_loss: 0.5806 - mlp_binary_accuracy: 0.7319 - mlp_auc_13: 0.8409\n",
      "------ mlp_binary_accuracy: 73.19%\t ----- mlp_auc_13: 84.09%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 5 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.2066 - siamese_loss: 1.1380 - mlp_loss: 0.6868 - mlp_binary_accuracy: 0.5614 - mlp_auc_14: 0.5882\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6381 - siamese_loss: 0.5713 - mlp_loss: 0.6675 - mlp_binary_accuracy: 0.6176 - mlp_auc_14: 0.6644\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5895 - siamese_loss: 0.5244 - mlp_loss: 0.6502 - mlp_binary_accuracy: 0.6520 - mlp_auc_14: 0.6976\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5644 - siamese_loss: 0.5014 - mlp_loss: 0.6298 - mlp_binary_accuracy: 0.6754 - mlp_auc_14: 0.7287\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5411 - siamese_loss: 0.4802 - mlp_loss: 0.6084 - mlp_binary_accuracy: 0.6996 - mlp_auc_14: 0.7545\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5168 - siamese_loss: 0.4582 - mlp_loss: 0.5859 - mlp_binary_accuracy: 0.7221 - mlp_auc_14: 0.7747\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5421 - siamese_loss: 0.4848 - mlp_loss: 0.5725 - mlp_binary_accuracy: 0.7304 - mlp_auc_14: 0.7868\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5190 - siamese_loss: 0.4631 - mlp_loss: 0.5589 - mlp_binary_accuracy: 0.7342 - mlp_auc_14: 0.7919\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5036 - siamese_loss: 0.4486 - mlp_loss: 0.5496 - mlp_binary_accuracy: 0.7397 - mlp_auc_14: 0.8006\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5103 - siamese_loss: 0.4560 - mlp_loss: 0.5430 - mlp_binary_accuracy: 0.7481 - mlp_auc_14: 0.8096\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5100 - siamese_loss: 0.4568 - mlp_loss: 0.5317 - mlp_binary_accuracy: 0.7459 - mlp_auc_14: 0.8137\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6731 - siamese_loss: 0.6196 - mlp_loss: 0.5350 - mlp_binary_accuracy: 0.7405 - mlp_auc_14: 0.8111\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5546 - siamese_loss: 0.5034 - mlp_loss: 0.5119 - mlp_binary_accuracy: 0.7550 - mlp_auc_14: 0.8267\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5234 - siamese_loss: 0.4727 - mlp_loss: 0.5071 - mlp_binary_accuracy: 0.7556 - mlp_auc_14: 0.8292\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - siamese_loss: 0.4228 - mlp_loss: 0.5363 - mlp_binary_accuracy: 0.7078 - mlp_auc_14: 0.8283\n",
      "------ mlp_binary_accuracy: 70.78%\t ----- mlp_auc_14: 82.83%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 6 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.3568 - siamese_loss: 1.2897 - mlp_loss: 0.6705 - mlp_binary_accuracy: 0.5926 - mlp_auc_15: 0.6278\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5895 - siamese_loss: 0.5265 - mlp_loss: 0.6302 - mlp_binary_accuracy: 0.6488 - mlp_auc_15: 0.7034\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6056 - siamese_loss: 0.5450 - mlp_loss: 0.6059 - mlp_binary_accuracy: 0.6728 - mlp_auc_15: 0.7358\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5654 - siamese_loss: 0.5068 - mlp_loss: 0.5862 - mlp_binary_accuracy: 0.7080 - mlp_auc_15: 0.7599\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5822 - siamese_loss: 0.5260 - mlp_loss: 0.5622 - mlp_binary_accuracy: 0.7221 - mlp_auc_15: 0.7840\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5249 - siamese_loss: 0.4712 - mlp_loss: 0.5367 - mlp_binary_accuracy: 0.7397 - mlp_auc_15: 0.8070\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4994 - siamese_loss: 0.4470 - mlp_loss: 0.5244 - mlp_binary_accuracy: 0.7427 - mlp_auc_15: 0.8172\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5238 - siamese_loss: 0.4725 - mlp_loss: 0.5130 - mlp_binary_accuracy: 0.7542 - mlp_auc_15: 0.8270\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4969 - siamese_loss: 0.4472 - mlp_loss: 0.4969 - mlp_binary_accuracy: 0.7622 - mlp_auc_15: 0.8388\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5071 - siamese_loss: 0.4579 - mlp_loss: 0.4921 - mlp_binary_accuracy: 0.7657 - mlp_auc_15: 0.8425\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5294 - siamese_loss: 0.4810 - mlp_loss: 0.4846 - mlp_binary_accuracy: 0.7737 - mlp_auc_15: 0.8480\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4712 - siamese_loss: 0.4242 - mlp_loss: 0.4698 - mlp_binary_accuracy: 0.7814 - mlp_auc_15: 0.8588\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5024 - siamese_loss: 0.4558 - mlp_loss: 0.4663 - mlp_binary_accuracy: 0.7830 - mlp_auc_15: 0.8601\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4717 - siamese_loss: 0.4250 - mlp_loss: 0.4666 - mlp_binary_accuracy: 0.7808 - mlp_auc_15: 0.8603\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4668 - siamese_loss: 0.4214 - mlp_loss: 0.4540 - mlp_binary_accuracy: 0.7862 - mlp_auc_15: 0.8686\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4513 - siamese_loss: 0.4060 - mlp_loss: 0.4537 - mlp_binary_accuracy: 0.7915 - mlp_auc_15: 0.8692\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4573 - siamese_loss: 0.4133 - mlp_loss: 0.4399 - mlp_binary_accuracy: 0.8019 - mlp_auc_15: 0.8771\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4472 - siamese_loss: 0.4028 - mlp_loss: 0.4444 - mlp_binary_accuracy: 0.7987 - mlp_auc_15: 0.8756\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4885 - siamese_loss: 0.4441 - mlp_loss: 0.4433 - mlp_binary_accuracy: 0.8029 - mlp_auc_15: 0.8757\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4569 - siamese_loss: 0.4143 - mlp_loss: 0.4265 - mlp_binary_accuracy: 0.8019 - mlp_auc_15: 0.8848\n",
      "Epoch 21/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4784 - siamese_loss: 0.4362 - mlp_loss: 0.4220 - mlp_binary_accuracy: 0.8052 - mlp_auc_15: 0.8867\n",
      "Epoch 22/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4398 - siamese_loss: 0.3980 - mlp_loss: 0.4176 - mlp_binary_accuracy: 0.8106 - mlp_auc_15: 0.8895\n",
      "Epoch 23/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5121 - siamese_loss: 0.4697 - mlp_loss: 0.4243 - mlp_binary_accuracy: 0.8058 - mlp_auc_15: 0.8861\n",
      "Epoch 24/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5175 - siamese_loss: 0.4746 - mlp_loss: 0.4290 - mlp_binary_accuracy: 0.8052 - mlp_auc_15: 0.8830\n",
      "Epoch 25/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5340 - siamese_loss: 0.4905 - mlp_loss: 0.4355 - mlp_binary_accuracy: 0.8007 - mlp_auc_15: 0.8799\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5406 - siamese_loss: 0.4979 - mlp_loss: 0.4267 - mlp_binary_accuracy: 0.8044 - mlp_auc_15: 0.8859\n",
      "Epoch 27/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4894 - siamese_loss: 0.4475 - mlp_loss: 0.4192 - mlp_binary_accuracy: 0.8066 - mlp_auc_15: 0.8893\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - siamese_loss: 0.4095 - mlp_loss: 0.5101 - mlp_binary_accuracy: 0.7768 - mlp_auc_15: 0.8455\n",
      "------ mlp_binary_accuracy: 77.68%\t ----- mlp_auc_15: 84.55%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 7 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.4940 - siamese_loss: 1.4256 - mlp_loss: 0.6843 - mlp_binary_accuracy: 0.5527 - mlp_auc_16: 0.5819\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6808 - siamese_loss: 0.6165 - mlp_loss: 0.6433 - mlp_binary_accuracy: 0.6333 - mlp_auc_16: 0.6816\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5862 - siamese_loss: 0.5243 - mlp_loss: 0.6195 - mlp_binary_accuracy: 0.6544 - mlp_auc_16: 0.7176\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5787 - siamese_loss: 0.5180 - mlp_loss: 0.6073 - mlp_binary_accuracy: 0.6665 - mlp_auc_16: 0.7341\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5778 - siamese_loss: 0.5180 - mlp_loss: 0.5973 - mlp_binary_accuracy: 0.6865 - mlp_auc_16: 0.7448\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5588 - siamese_loss: 0.5004 - mlp_loss: 0.5837 - mlp_binary_accuracy: 0.7048 - mlp_auc_16: 0.7604\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5431 - siamese_loss: 0.4853 - mlp_loss: 0.5774 - mlp_binary_accuracy: 0.7046 - mlp_auc_16: 0.7667\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5106 - siamese_loss: 0.4545 - mlp_loss: 0.5614 - mlp_binary_accuracy: 0.7197 - mlp_auc_16: 0.7824\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5271 - siamese_loss: 0.4723 - mlp_loss: 0.5488 - mlp_binary_accuracy: 0.7284 - mlp_auc_16: 0.7947\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5142 - siamese_loss: 0.4608 - mlp_loss: 0.5342 - mlp_binary_accuracy: 0.7375 - mlp_auc_16: 0.8083\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5264 - siamese_loss: 0.4742 - mlp_loss: 0.5218 - mlp_binary_accuracy: 0.7471 - mlp_auc_16: 0.8190\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5031 - siamese_loss: 0.4522 - mlp_loss: 0.5090 - mlp_binary_accuracy: 0.7526 - mlp_auc_16: 0.8289\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5256 - siamese_loss: 0.4760 - mlp_loss: 0.4960 - mlp_binary_accuracy: 0.7667 - mlp_auc_16: 0.8389\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4895 - siamese_loss: 0.4405 - mlp_loss: 0.4898 - mlp_binary_accuracy: 0.7657 - mlp_auc_16: 0.8433\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4584 - siamese_loss: 0.4105 - mlp_loss: 0.4785 - mlp_binary_accuracy: 0.7729 - mlp_auc_16: 0.8513\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4964 - siamese_loss: 0.4485 - mlp_loss: 0.4787 - mlp_binary_accuracy: 0.7719 - mlp_auc_16: 0.8514\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4834 - siamese_loss: 0.4368 - mlp_loss: 0.4665 - mlp_binary_accuracy: 0.7804 - mlp_auc_16: 0.8594\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4556 - siamese_loss: 0.4089 - mlp_loss: 0.4676 - mlp_binary_accuracy: 0.7800 - mlp_auc_16: 0.8592\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4958 - siamese_loss: 0.4500 - mlp_loss: 0.4580 - mlp_binary_accuracy: 0.7864 - mlp_auc_16: 0.8650\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4666 - siamese_loss: 0.4209 - mlp_loss: 0.4565 - mlp_binary_accuracy: 0.7862 - mlp_auc_16: 0.8664\n",
      "Epoch 21/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4497 - siamese_loss: 0.4050 - mlp_loss: 0.4469 - mlp_binary_accuracy: 0.7921 - mlp_auc_16: 0.8722\n",
      "Epoch 22/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4524 - siamese_loss: 0.4077 - mlp_loss: 0.4468 - mlp_binary_accuracy: 0.7961 - mlp_auc_16: 0.8726\n",
      "Epoch 23/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4820 - siamese_loss: 0.4374 - mlp_loss: 0.4454 - mlp_binary_accuracy: 0.7929 - mlp_auc_16: 0.8733\n",
      "Epoch 24/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4586 - siamese_loss: 0.4149 - mlp_loss: 0.4370 - mlp_binary_accuracy: 0.8070 - mlp_auc_16: 0.8795\n",
      "Epoch 25/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4543 - siamese_loss: 0.4107 - mlp_loss: 0.4365 - mlp_binary_accuracy: 0.8066 - mlp_auc_16: 0.8793\n",
      "Epoch 26/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4582 - siamese_loss: 0.4152 - mlp_loss: 0.4299 - mlp_binary_accuracy: 0.8027 - mlp_auc_16: 0.8829\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - siamese_loss: 0.4260 - mlp_loss: 0.5320 - mlp_binary_accuracy: 0.7695 - mlp_auc_16: 0.8468\n",
      "------ mlp_binary_accuracy: 76.95%\t ----- mlp_auc_16: 84.68%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 8 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.9370 - siamese_loss: 0.8694 - mlp_loss: 0.6764 - mlp_binary_accuracy: 0.5722 - mlp_auc_17: 0.6021\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6244 - siamese_loss: 0.5604 - mlp_loss: 0.6406 - mlp_binary_accuracy: 0.6403 - mlp_auc_17: 0.6817\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5390 - siamese_loss: 0.4776 - mlp_loss: 0.6141 - mlp_binary_accuracy: 0.6597 - mlp_auc_17: 0.7238\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5506 - siamese_loss: 0.4913 - mlp_loss: 0.5924 - mlp_binary_accuracy: 0.6859 - mlp_auc_17: 0.7517\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4849 - siamese_loss: 0.4279 - mlp_loss: 0.5698 - mlp_binary_accuracy: 0.7010 - mlp_auc_17: 0.7750\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4881 - siamese_loss: 0.4329 - mlp_loss: 0.5516 - mlp_binary_accuracy: 0.7177 - mlp_auc_17: 0.7927\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4988 - siamese_loss: 0.4451 - mlp_loss: 0.5374 - mlp_binary_accuracy: 0.7320 - mlp_auc_17: 0.8051\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4654 - siamese_loss: 0.4132 - mlp_loss: 0.5220 - mlp_binary_accuracy: 0.7393 - mlp_auc_17: 0.8182\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4477 - siamese_loss: 0.3965 - mlp_loss: 0.5121 - mlp_binary_accuracy: 0.7485 - mlp_auc_17: 0.8268\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4589 - siamese_loss: 0.4087 - mlp_loss: 0.5013 - mlp_binary_accuracy: 0.7590 - mlp_auc_17: 0.8346\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4568 - siamese_loss: 0.4070 - mlp_loss: 0.4980 - mlp_binary_accuracy: 0.7584 - mlp_auc_17: 0.8377\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4880 - siamese_loss: 0.4378 - mlp_loss: 0.5020 - mlp_binary_accuracy: 0.7560 - mlp_auc_17: 0.8342\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5617 - siamese_loss: 0.5115 - mlp_loss: 0.5023 - mlp_binary_accuracy: 0.7562 - mlp_auc_17: 0.8349\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5107 - siamese_loss: 0.4615 - mlp_loss: 0.4923 - mlp_binary_accuracy: 0.7683 - mlp_auc_17: 0.8422\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3758 - siamese_loss: 0.3247 - mlp_loss: 0.5110 - mlp_binary_accuracy: 0.7623 - mlp_auc_17: 0.8349\n",
      "------ mlp_binary_accuracy: 76.23%\t ----- mlp_auc_17: 83.49%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 9 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.1996 - siamese_loss: 1.1314 - mlp_loss: 0.6818 - mlp_binary_accuracy: 0.5579 - mlp_auc_18: 0.5932\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5939 - siamese_loss: 0.5297 - mlp_loss: 0.6417 - mlp_binary_accuracy: 0.6329 - mlp_auc_18: 0.6825\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5813 - siamese_loss: 0.5198 - mlp_loss: 0.6157 - mlp_binary_accuracy: 0.6687 - mlp_auc_18: 0.7240\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5854 - siamese_loss: 0.5257 - mlp_loss: 0.5971 - mlp_binary_accuracy: 0.6951 - mlp_auc_18: 0.7476\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5728 - siamese_loss: 0.5147 - mlp_loss: 0.5817 - mlp_binary_accuracy: 0.7040 - mlp_auc_18: 0.7641\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5430 - siamese_loss: 0.4866 - mlp_loss: 0.5640 - mlp_binary_accuracy: 0.7167 - mlp_auc_18: 0.7815\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5340 - siamese_loss: 0.4789 - mlp_loss: 0.5507 - mlp_binary_accuracy: 0.7272 - mlp_auc_18: 0.7937\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5240 - siamese_loss: 0.4706 - mlp_loss: 0.5348 - mlp_binary_accuracy: 0.7391 - mlp_auc_18: 0.8085\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5323 - siamese_loss: 0.4797 - mlp_loss: 0.5264 - mlp_binary_accuracy: 0.7373 - mlp_auc_18: 0.8153\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5009 - siamese_loss: 0.4498 - mlp_loss: 0.5110 - mlp_binary_accuracy: 0.7562 - mlp_auc_18: 0.8279\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5354 - siamese_loss: 0.4844 - mlp_loss: 0.5096 - mlp_binary_accuracy: 0.7502 - mlp_auc_18: 0.8290\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4933 - siamese_loss: 0.4439 - mlp_loss: 0.4948 - mlp_binary_accuracy: 0.7604 - mlp_auc_18: 0.8404\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4793 - siamese_loss: 0.4304 - mlp_loss: 0.4885 - mlp_binary_accuracy: 0.7755 - mlp_auc_18: 0.8452\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4693 - siamese_loss: 0.4209 - mlp_loss: 0.4841 - mlp_binary_accuracy: 0.7761 - mlp_auc_18: 0.8481\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4715 - siamese_loss: 0.4242 - mlp_loss: 0.4736 - mlp_binary_accuracy: 0.7792 - mlp_auc_18: 0.8557\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5096 - siamese_loss: 0.4620 - mlp_loss: 0.4755 - mlp_binary_accuracy: 0.7794 - mlp_auc_18: 0.8541\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5700 - siamese_loss: 0.5229 - mlp_loss: 0.4706 - mlp_binary_accuracy: 0.7792 - mlp_auc_18: 0.8580\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4999 - siamese_loss: 0.4535 - mlp_loss: 0.4638 - mlp_binary_accuracy: 0.7818 - mlp_auc_18: 0.8625\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4689 - siamese_loss: 0.4230 - mlp_loss: 0.4591 - mlp_binary_accuracy: 0.7840 - mlp_auc_18: 0.8650\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5430 - siamese_loss: 0.4957 - mlp_loss: 0.4730 - mlp_binary_accuracy: 0.7782 - mlp_auc_18: 0.8560\n",
      "Epoch 21/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5998 - siamese_loss: 0.5527 - mlp_loss: 0.4707 - mlp_binary_accuracy: 0.7794 - mlp_auc_18: 0.8571\n",
      "Epoch 22/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5434 - siamese_loss: 0.4972 - mlp_loss: 0.4621 - mlp_binary_accuracy: 0.7824 - mlp_auc_18: 0.8637\n",
      "Epoch 23/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5250 - siamese_loss: 0.4791 - mlp_loss: 0.4587 - mlp_binary_accuracy: 0.7834 - mlp_auc_18: 0.8651\n",
      "Epoch 24/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4877 - siamese_loss: 0.4425 - mlp_loss: 0.4521 - mlp_binary_accuracy: 0.7896 - mlp_auc_18: 0.8697\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4536 - siamese_loss: 0.3934 - mlp_loss: 0.6016 - mlp_binary_accuracy: 0.7024 - mlp_auc_18: 0.8296\n",
      "------ mlp_binary_accuracy: 70.24%\t ----- mlp_auc_18: 82.96%\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 10 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 1.7688 - siamese_loss: 1.7009 - mlp_loss: 0.6788 - mlp_binary_accuracy: 0.5783 - mlp_auc_19: 0.5963\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.7567 - siamese_loss: 0.6925 - mlp_loss: 0.6422 - mlp_binary_accuracy: 0.6365 - mlp_auc_19: 0.6781\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6134 - siamese_loss: 0.5509 - mlp_loss: 0.6246 - mlp_binary_accuracy: 0.6567 - mlp_auc_19: 0.7059\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5561 - siamese_loss: 0.4952 - mlp_loss: 0.6094 - mlp_binary_accuracy: 0.6712 - mlp_auc_19: 0.7306\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5534 - siamese_loss: 0.4939 - mlp_loss: 0.5952 - mlp_binary_accuracy: 0.6812 - mlp_auc_19: 0.7476\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5383 - siamese_loss: 0.4808 - mlp_loss: 0.5758 - mlp_binary_accuracy: 0.7076 - mlp_auc_19: 0.7705\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5270 - siamese_loss: 0.4707 - mlp_loss: 0.5623 - mlp_binary_accuracy: 0.7221 - mlp_auc_19: 0.7830\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5333 - siamese_loss: 0.4785 - mlp_loss: 0.5487 - mlp_binary_accuracy: 0.7328 - mlp_auc_19: 0.7947\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5338 - siamese_loss: 0.4794 - mlp_loss: 0.5440 - mlp_binary_accuracy: 0.7280 - mlp_auc_19: 0.7992\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5565 - siamese_loss: 0.5031 - mlp_loss: 0.5341 - mlp_binary_accuracy: 0.7373 - mlp_auc_19: 0.8081\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5390 - siamese_loss: 0.4868 - mlp_loss: 0.5218 - mlp_binary_accuracy: 0.7473 - mlp_auc_19: 0.8185\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5124 - siamese_loss: 0.4606 - mlp_loss: 0.5182 - mlp_binary_accuracy: 0.7463 - mlp_auc_19: 0.8223\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5111 - siamese_loss: 0.4604 - mlp_loss: 0.5066 - mlp_binary_accuracy: 0.7570 - mlp_auc_19: 0.8321\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4882 - siamese_loss: 0.4379 - mlp_loss: 0.5028 - mlp_binary_accuracy: 0.7612 - mlp_auc_19: 0.8347\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5367 - siamese_loss: 0.4865 - mlp_loss: 0.5022 - mlp_binary_accuracy: 0.7612 - mlp_auc_19: 0.8354\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4846 - siamese_loss: 0.4355 - mlp_loss: 0.4912 - mlp_binary_accuracy: 0.7665 - mlp_auc_19: 0.8431\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4801 - siamese_loss: 0.4310 - mlp_loss: 0.4911 - mlp_binary_accuracy: 0.7647 - mlp_auc_19: 0.8432\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4725 - siamese_loss: 0.4241 - mlp_loss: 0.4836 - mlp_binary_accuracy: 0.7721 - mlp_auc_19: 0.8485\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4639 - siamese_loss: 0.4161 - mlp_loss: 0.4777 - mlp_binary_accuracy: 0.7687 - mlp_auc_19: 0.8526\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4771 - siamese_loss: 0.4299 - mlp_loss: 0.4716 - mlp_binary_accuracy: 0.7769 - mlp_auc_19: 0.8569\n",
      "Epoch 21/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4489 - siamese_loss: 0.4027 - mlp_loss: 0.4616 - mlp_binary_accuracy: 0.7830 - mlp_auc_19: 0.8631\n",
      "Epoch 22/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4328 - siamese_loss: 0.3868 - mlp_loss: 0.4602 - mlp_binary_accuracy: 0.7902 - mlp_auc_19: 0.8640\n",
      "Epoch 23/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4209 - siamese_loss: 0.3748 - mlp_loss: 0.4607 - mlp_binary_accuracy: 0.7872 - mlp_auc_19: 0.8647\n",
      "Epoch 24/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4644 - siamese_loss: 0.4182 - mlp_loss: 0.4619 - mlp_binary_accuracy: 0.7838 - mlp_auc_19: 0.8623\n",
      "Epoch 25/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4656 - siamese_loss: 0.4199 - mlp_loss: 0.4573 - mlp_binary_accuracy: 0.7860 - mlp_auc_19: 0.8662\n",
      "Epoch 26/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5243 - siamese_loss: 0.4785 - mlp_loss: 0.4583 - mlp_binary_accuracy: 0.7864 - mlp_auc_19: 0.8650\n",
      "Epoch 27/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5189 - siamese_loss: 0.4732 - mlp_loss: 0.4574 - mlp_binary_accuracy: 0.7848 - mlp_auc_19: 0.8659\n",
      "Epoch 28/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5207 - siamese_loss: 0.4758 - mlp_loss: 0.4487 - mlp_binary_accuracy: 0.7902 - mlp_auc_19: 0.8715\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5438 - siamese_loss: 0.4898 - mlp_loss: 0.5400 - mlp_binary_accuracy: 0.7223 - mlp_auc_19: 0.8678\n",
      "------ mlp_binary_accuracy: 72.23%\t ----- mlp_auc_19: 86.78%\n",
      "十折性能均值：-------- ave_acc: 73.87% (+/- 2.61%)\t ----- ave_auc_mlp:83.78% (+/- 1.85%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics  import roc_curve,auc,roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "cvacc,cvauc_mlp,cvpre,cvpre_top,cvrec,cvauc_sia=[],[],[],[],[],[]\n",
    "i =1\n",
    "\n",
    "\n",
    "neg_to_pos= 1\n",
    "rus = RandomUnderSampler(sampling_strategy=neg_to_pos,random_state=1) \n",
    "rus_dfmA,rus_y = rus.fit_resample(X=disA_fea_mat,y=y)\n",
    "rus_dfmB,rus_y2 = rus.fit_resample(X=disB_fea_mat,y=y)\n",
    "print('rus_y的长度:',len(rus_y))\n",
    "\n",
    "rus_mesh_A,rus_y3= rus.fit_resample(X=mesh_label_A,y=y)\n",
    "rus_mesh_B,rus_y4 = rus.fit_resample(X=mesh_label_B,y=y)\n",
    "print(\"rus_mesh_B的长度：\",len(rus_mesh_B))\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed) \n",
    "python_random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "Kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "for train,test in Kfold.split(X=rus_dfmA,y=rus_y):\n",
    "    ###############################################################################################\n",
    " \n",
    "    input_shape=(385)\n",
    "    base_network = create_base_network(input_shape)\n",
    "    \n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "    input_mesh_a = Input(shape=24)\n",
    "    input_mesh_b = Input(shape=24)\n",
    "    \n",
    "\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "\n",
    "    eucl_model = create_euclLayer(processed_a.shape[-1])\n",
    "    eucl_out = eucl_model([processed_a,processed_b]) \n",
    "    \n",
    "    \n",
    "    concat_fea = tf.keras.layers.concatenate([processed_a,input_mesh_a,processed_b,input_mesh_b],axis=-1)\n",
    "    print(\"concat_fea的shape：\",concat_fea.shape) \n",
    "    \n",
    "    MLP = create_MLP(concat_fea.shape[-1])\n",
    "    MLP_out = MLP(concat_fea)\n",
    "    \n",
    "    model = Model(inputs=[input_a,input_b,input_mesh_a,input_mesh_b], outputs=[eucl_out,MLP_out])\n",
    "    \n",
    "    \"\"\"L2\"\"\"\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer,'kernel_regularizer'):\n",
    "            layer.kernel_regularizer = tf.keras.regularizers.l2(0.001)\n",
    "        \n",
    "    #####################################################################################################################\n",
    "\n",
    "    print(\"-------------------------------------Kfold: {} iter-----------------------------------------\".format(i))\n",
    "    i+=1\n",
    "\n",
    "    rms = RMSprop()\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=5)\n",
    "    \n",
    "    my_loss = {\"siamese\":contrastive_loss,\"mlp\":tf.keras.losses.BinaryCrossentropy()}\n",
    "    my_loss_weight = {\"siamese\":1,\"mlp\":0.1}\n",
    "    my_metrics ={ \"mlp\":[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()]} #tf.keras.metrics.Precision(top_k=len(rus_y)//100)\n",
    "    \n",
    "    model.compile(\n",
    "#         loss= [tfa.losses.ContrastiveLoss(),tf.keras.losses.BinaryCrossentropy()],\n",
    "#         loss_weights=[0.01,1],\n",
    "#         metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    "        \n",
    "        loss= my_loss,\n",
    "        loss_weights=my_loss_weight,\n",
    "        metrics=my_metrics,\n",
    "        \n",
    "        optimizer=rms,\n",
    "    )\n",
    "    \n",
    "    # fit()中 shuffle=True\n",
    "    model.fit([rus_dfmA[train],rus_dfmB[train],rus_mesh_A[train],rus_mesh_B[train]],\n",
    "              [rus_y[train],rus_y[train]],\n",
    "              \n",
    "              batch_size=None,\n",
    "              epochs=200,\n",
    "              callbacks=callback,\n",
    "              shuffle=True,\n",
    "             )\n",
    "    \n",
    "    scores = model.evaluate([rus_dfmA[test],rus_dfmB[test],rus_mesh_A[test],rus_mesh_B[test]],\n",
    "                            [rus_y[test],rus_y[test]],\n",
    "                            verbose=1,\n",
    "                            batch_size=32)\n",
    "    \n",
    "    predict_res = model.predict([rus_dfmA[test],rus_dfmB[test],rus_mesh_A[test],rus_mesh_B[test]])\n",
    "    \n",
    "    cvacc.append(scores[-2] * 100)\n",
    "    cvauc_mlp.append(scores[-1] * 100)\n",
    "    cvauc_sia.append(scores[-3] * 100)\n",
    "    \n",
    "    print(\"------ %s: %.2f%%\\t ----- %s: %.2f%%\" % \n",
    "           (model.metrics_names[-2],scores[-2]*100, model.metrics_names[-1],scores[-1]*100))\n",
    "     \n",
    "print(\"十折性能均值：-------- ave_acc: %.2f%% (+/- %.2f%%)\\t ----- ave_auc_mlp:%.2f%% (+/- %.2f%%)\" % \n",
    "      (np.mean(cvacc), np.std(cvacc),np.mean(cvauc_mlp), np.std(cvauc_mlp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8aa262eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9000725426187886\n",
      "551\n",
      "[4544 4550 4555 4593 4606 4620 4651 4654 4666 4677 4681 4686 4699 4711\n",
      " 4714 4725 4743 4748 4756 4782 4811 4814 4828 4833 4844 4851 4881 4886\n",
      " 4887 4896 4914 4927 4928 4939 4962 4964 4968 4970 4981 4982 4985 5005\n",
      " 5020 5023 5026 5037 5040 5047 5060 5081 5084 5085 5087 5107 5115 5116\n",
      " 5129 5152 5169 5170 5178 5202 5204 5225 5233 5235 5241 5262 5264 5267\n",
      " 5288 5289 5294 5296 5299 5314 5324 5326 5332 5336 5337 5346 5372 5377\n",
      " 5384 5387 5394 5400 5404 5412 5425 5435 5444 5450 5456 5461 5476 5481\n",
      " 5496]\n",
      "42195\n",
      "5514\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(len(mesh_label_A[train])/5514)\n",
    "print(len(test))\n",
    "print(test[-100:-1])\n",
    "print(len(mesh_label_A))\n",
    "print(len(rus_mesh_A))\n",
    "print(rus_y3[:100])\n",
    "print(rus_y4[-100:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3c47232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test virtual mesh feature\"\"\"\n",
    "rand_matA = nvp.random.randint(1,size=(42195,24))\n",
    "rand_matB = np.random.randint(1,size=(42195,24))\n",
    "\n",
    "for i in range(42195):\n",
    "    rand_matA[i][np.random.randint(24)]=1\n",
    "    rand_matB[i][np.random.randint(24)]=1\n",
    "print(rand_matA[:1])\n",
    "print(rand_matB[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2c810",
   "metadata": {},
   "source": [
    "###  results\n",
    "#### test virtual mesh feature\n",
    "    1、undersampling-------- ave_acc: 79.47% (+/- 3.32%)\t ----- ave_auc_mlp:87.95% (+/- 2.23%)\n",
    "    2、random 0/1\n",
    "        all random-------- ave_acc: 66.03% (+/- 2.48%)\t ----- ave_auc_mlp:72.06% (+/- 1.61%)\n",
    "        one random 1 for each disease mesh feature-------- ave_acc: 70.82% (+/- 3.30%)\t ----- ave_auc_mlp:77.01% (+/- 3.62%)\n",
    "        shuffle mesh one-hot-------- ave_acc: 71.38% (+/- 1.90%)\t ----- ave_auc_mlp:77.56% (+/- 2.78%)\n",
    "#### test loss weights\n",
    "    sia:1,mlp:1:-------- ave_acc: 74.14% (+/- 4.36%)\t ----- ave_auc_mlp:83.77% (+/- 3.00%)\n",
    "    sia:0.1,mlp:1:-------- ave_acc: 76.91% (+/- 2.57%)\t ----- ave_auc_mlp:85.23% (+/- 1.73%)\n",
    "    sia:0.01,mlp:1:-------- ave_acc: 77.98% (+/- 2.79%)\t ----- ave_auc_mlp:86.88% (+/- 2.80%)\n",
    "    \n",
    "    sia:1,mlp:0.1:-------- ave_acc: 73.87% (+/- 2.61%)\t ----- ave_auc_mlp:83.78% (+/- 1.85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf3cf4",
   "metadata": {},
   "source": [
    "## ramdom split test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7dc6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mesh_label_A=mesh_label_A.astype(np.float32)\n",
    "mesh_label_B=mesh_label_B.astype(np.float32)\n",
    "\n",
    "y=y.astype(np.float32)\n",
    "\n",
    "y=np.array(y)\n",
    "\n",
    "disA_fea_mat=np.array(disA_fea_mat)\n",
    "disB_fea_mat=np.array(disB_fea_mat)\n",
    "\n",
    "mesh_label_A = np.array(mesh_label_A)\n",
    "mesh_label_B = np.array(mesh_label_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a26573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rus_y的长度: 5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'PYTHONHASHSEED' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 1 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6741 - siamese_loss: 2.7143 - mlp_loss: 0.6741 - mlp_binary_accuracy: 0.5734 - mlp_auc_56: 0.6131\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6408 - siamese_loss: 1.9223 - mlp_loss: 0.6408 - mlp_binary_accuracy: 0.6344 - mlp_auc_56: 0.6852\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6275 - siamese_loss: 1.5244 - mlp_loss: 0.6275 - mlp_binary_accuracy: 0.6513 - mlp_auc_56: 0.7042\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6075 - siamese_loss: 1.9501 - mlp_loss: 0.6075 - mlp_binary_accuracy: 0.6803 - mlp_auc_56: 0.7298\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5939 - siamese_loss: 1.9327 - mlp_loss: 0.5939 - mlp_binary_accuracy: 0.6888 - mlp_auc_56: 0.7473\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5760 - siamese_loss: 2.3063 - mlp_loss: 0.5760 - mlp_binary_accuracy: 0.7045 - mlp_auc_56: 0.7667\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5640 - siamese_loss: 2.4462 - mlp_loss: 0.5640 - mlp_binary_accuracy: 0.7198 - mlp_auc_56: 0.7813\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5480 - siamese_loss: 2.4618 - mlp_loss: 0.5480 - mlp_binary_accuracy: 0.7289 - mlp_auc_56: 0.7966\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5390 - siamese_loss: 3.1953 - mlp_loss: 0.5390 - mlp_binary_accuracy: 0.7342 - mlp_auc_56: 0.8042\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5159 - siamese_loss: 3.1991 - mlp_loss: 0.5159 - mlp_binary_accuracy: 0.7541 - mlp_auc_56: 0.8242\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5041 - siamese_loss: 2.5671 - mlp_loss: 0.5041 - mlp_binary_accuracy: 0.7627 - mlp_auc_56: 0.8344\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4886 - siamese_loss: 2.2155 - mlp_loss: 0.4886 - mlp_binary_accuracy: 0.7674 - mlp_auc_56: 0.8463\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4847 - siamese_loss: 2.1002 - mlp_loss: 0.4847 - mlp_binary_accuracy: 0.7685 - mlp_auc_56: 0.8488\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4799 - siamese_loss: 1.7538 - mlp_loss: 0.4799 - mlp_binary_accuracy: 0.7710 - mlp_auc_56: 0.8509\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4624 - siamese_loss: 1.6765 - mlp_loss: 0.4624 - mlp_binary_accuracy: 0.7858 - mlp_auc_56: 0.8621\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4555 - siamese_loss: 1.8025 - mlp_loss: 0.4555 - mlp_binary_accuracy: 0.7891 - mlp_auc_56: 0.8672\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4551 - siamese_loss: 2.0283 - mlp_loss: 0.4551 - mlp_binary_accuracy: 0.7942 - mlp_auc_56: 0.8682\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4506 - siamese_loss: 1.9079 - mlp_loss: 0.4506 - mlp_binary_accuracy: 0.7876 - mlp_auc_56: 0.8700\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4457 - siamese_loss: 2.1409 - mlp_loss: 0.4457 - mlp_binary_accuracy: 0.7924 - mlp_auc_56: 0.8728\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4476 - siamese_loss: 2.2754 - mlp_loss: 0.4476 - mlp_binary_accuracy: 0.7957 - mlp_auc_56: 0.8725\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4434 - siamese_loss: 2.5789 - mlp_loss: 0.4434 - mlp_binary_accuracy: 0.7924 - mlp_auc_56: 0.8741\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4320 - siamese_loss: 2.3003 - mlp_loss: 0.4320 - mlp_binary_accuracy: 0.7999 - mlp_auc_56: 0.8819\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4413 - siamese_loss: 2.6201 - mlp_loss: 0.4413 - mlp_binary_accuracy: 0.7957 - mlp_auc_56: 0.8758\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4373 - siamese_loss: 2.5792 - mlp_loss: 0.4373 - mlp_binary_accuracy: 0.7994 - mlp_auc_56: 0.8785\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4421 - siamese_loss: 2.9985 - mlp_loss: 0.4421 - mlp_binary_accuracy: 0.7989 - mlp_auc_56: 0.8758\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4284 - siamese_loss: 2.9545 - mlp_loss: 0.4284 - mlp_binary_accuracy: 0.8060 - mlp_auc_56: 0.8843\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4253 - siamese_loss: 3.0669 - mlp_loss: 0.4253 - mlp_binary_accuracy: 0.8020 - mlp_auc_56: 0.8855\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4285 - siamese_loss: 3.0278 - mlp_loss: 0.4285 - mlp_binary_accuracy: 0.7984 - mlp_auc_56: 0.8835\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4139 - siamese_loss: 2.5142 - mlp_loss: 0.4139 - mlp_binary_accuracy: 0.8078 - mlp_auc_56: 0.8915\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4158 - siamese_loss: 2.9591 - mlp_loss: 0.4158 - mlp_binary_accuracy: 0.8120 - mlp_auc_56: 0.8912\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4171 - siamese_loss: 2.9155 - mlp_loss: 0.4171 - mlp_binary_accuracy: 0.8093 - mlp_auc_56: 0.8898\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4089 - siamese_loss: 3.3801 - mlp_loss: 0.4089 - mlp_binary_accuracy: 0.8113 - mlp_auc_56: 0.8952\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4094 - siamese_loss: 3.3769 - mlp_loss: 0.4094 - mlp_binary_accuracy: 0.8146 - mlp_auc_56: 0.8938\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4041 - siamese_loss: 3.2181 - mlp_loss: 0.4041 - mlp_binary_accuracy: 0.8080 - mlp_auc_56: 0.8967\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4104 - siamese_loss: 3.3256 - mlp_loss: 0.4104 - mlp_binary_accuracy: 0.8176 - mlp_auc_56: 0.8938\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4056 - siamese_loss: 3.1264 - mlp_loss: 0.4056 - mlp_binary_accuracy: 0.8125 - mlp_auc_56: 0.8963\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4086 - siamese_loss: 3.3139 - mlp_loss: 0.4086 - mlp_binary_accuracy: 0.8095 - mlp_auc_56: 0.8947\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4043 - siamese_loss: 3.3937 - mlp_loss: 0.4043 - mlp_binary_accuracy: 0.8156 - mlp_auc_56: 0.8964\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3979 - siamese_loss: 2.5101 - mlp_loss: 0.3979 - mlp_binary_accuracy: 0.8216 - mlp_auc_56: 0.8994\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3999 - siamese_loss: 2.5136 - mlp_loss: 0.3999 - mlp_binary_accuracy: 0.8108 - mlp_auc_56: 0.8987\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3970 - siamese_loss: 2.8830 - mlp_loss: 0.3970 - mlp_binary_accuracy: 0.8181 - mlp_auc_56: 0.9003\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4038 - siamese_loss: 3.0269 - mlp_loss: 0.4038 - mlp_binary_accuracy: 0.8166 - mlp_auc_56: 0.8979\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3899 - siamese_loss: 2.8163 - mlp_loss: 0.3899 - mlp_binary_accuracy: 0.8219 - mlp_auc_56: 0.9049\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3856 - siamese_loss: 2.7203 - mlp_loss: 0.3856 - mlp_binary_accuracy: 0.8226 - mlp_auc_56: 0.9070\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3776 - siamese_loss: 2.6008 - mlp_loss: 0.3776 - mlp_binary_accuracy: 0.8244 - mlp_auc_56: 0.9096\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3850 - siamese_loss: 2.6518 - mlp_loss: 0.3850 - mlp_binary_accuracy: 0.8246 - mlp_auc_56: 0.9063\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3847 - siamese_loss: 2.6106 - mlp_loss: 0.3847 - mlp_binary_accuracy: 0.8241 - mlp_auc_56: 0.9062\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3814 - siamese_loss: 2.8330 - mlp_loss: 0.3814 - mlp_binary_accuracy: 0.8264 - mlp_auc_56: 0.9078\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3862 - siamese_loss: 2.9838 - mlp_loss: 0.3862 - mlp_binary_accuracy: 0.8199 - mlp_auc_56: 0.9056\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3730 - siamese_loss: 3.2891 - mlp_loss: 0.3730 - mlp_binary_accuracy: 0.8347 - mlp_auc_56: 0.9127\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3829 - siamese_loss: 3.4932 - mlp_loss: 0.3829 - mlp_binary_accuracy: 0.8282 - mlp_auc_56: 0.9079\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3759 - siamese_loss: 3.3573 - mlp_loss: 0.3759 - mlp_binary_accuracy: 0.8274 - mlp_auc_56: 0.9107\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3711 - siamese_loss: 3.4164 - mlp_loss: 0.3711 - mlp_binary_accuracy: 0.8312 - mlp_auc_56: 0.9137\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3705 - siamese_loss: 3.6275 - mlp_loss: 0.3705 - mlp_binary_accuracy: 0.8292 - mlp_auc_56: 0.9135\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3693 - siamese_loss: 3.3812 - mlp_loss: 0.3693 - mlp_binary_accuracy: 0.8274 - mlp_auc_56: 0.9135\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3592 - siamese_loss: 3.4738 - mlp_loss: 0.3592 - mlp_binary_accuracy: 0.8382 - mlp_auc_56: 0.9196\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3608 - siamese_loss: 3.7690 - mlp_loss: 0.3608 - mlp_binary_accuracy: 0.8357 - mlp_auc_56: 0.9181\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3636 - siamese_loss: 3.7785 - mlp_loss: 0.3636 - mlp_binary_accuracy: 0.8380 - mlp_auc_56: 0.9168\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3729 - siamese_loss: 3.4550 - mlp_loss: 0.3729 - mlp_binary_accuracy: 0.8267 - mlp_auc_56: 0.9130\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3672 - siamese_loss: 3.7006 - mlp_loss: 0.3672 - mlp_binary_accuracy: 0.8267 - mlp_auc_56: 0.9154\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3581 - siamese_loss: 3.7209 - mlp_loss: 0.3581 - mlp_binary_accuracy: 0.8342 - mlp_auc_56: 0.9188\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3649 - siamese_loss: 3.0959 - mlp_loss: 0.3649 - mlp_binary_accuracy: 0.8332 - mlp_auc_56: 0.9153\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3622 - siamese_loss: 3.3738 - mlp_loss: 0.3622 - mlp_binary_accuracy: 0.8380 - mlp_auc_56: 0.9169\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3571 - siamese_loss: 3.4885 - mlp_loss: 0.3571 - mlp_binary_accuracy: 0.8375 - mlp_auc_56: 0.9198\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3639 - siamese_loss: 3.8470 - mlp_loss: 0.3639 - mlp_binary_accuracy: 0.8357 - mlp_auc_56: 0.9162\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3633 - siamese_loss: 4.1754 - mlp_loss: 0.3633 - mlp_binary_accuracy: 0.8362 - mlp_auc_56: 0.9167\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3655 - siamese_loss: 4.6166 - mlp_loss: 0.3655 - mlp_binary_accuracy: 0.8380 - mlp_auc_56: 0.9163\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3539 - siamese_loss: 4.4066 - mlp_loss: 0.3539 - mlp_binary_accuracy: 0.8410 - mlp_auc_56: 0.9212\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3543 - siamese_loss: 4.3719 - mlp_loss: 0.3543 - mlp_binary_accuracy: 0.8423 - mlp_auc_56: 0.9216\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3528 - siamese_loss: 4.0033 - mlp_loss: 0.3528 - mlp_binary_accuracy: 0.8382 - mlp_auc_56: 0.9213\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3481 - siamese_loss: 3.8785 - mlp_loss: 0.3481 - mlp_binary_accuracy: 0.8445 - mlp_auc_56: 0.9242\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3512 - siamese_loss: 3.9849 - mlp_loss: 0.3512 - mlp_binary_accuracy: 0.8420 - mlp_auc_56: 0.9231\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3450 - siamese_loss: 3.9894 - mlp_loss: 0.3450 - mlp_binary_accuracy: 0.8390 - mlp_auc_56: 0.9247\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3476 - siamese_loss: 3.4131 - mlp_loss: 0.3476 - mlp_binary_accuracy: 0.8433 - mlp_auc_56: 0.9244\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3421 - siamese_loss: 3.6624 - mlp_loss: 0.3421 - mlp_binary_accuracy: 0.8483 - mlp_auc_56: 0.9257\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3438 - siamese_loss: 3.6623 - mlp_loss: 0.3438 - mlp_binary_accuracy: 0.8400 - mlp_auc_56: 0.9245\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3406 - siamese_loss: 3.9912 - mlp_loss: 0.3406 - mlp_binary_accuracy: 0.8461 - mlp_auc_56: 0.9277\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3485 - siamese_loss: 4.5429 - mlp_loss: 0.3485 - mlp_binary_accuracy: 0.8413 - mlp_auc_56: 0.9236\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3426 - siamese_loss: 4.2338 - mlp_loss: 0.3426 - mlp_binary_accuracy: 0.8418 - mlp_auc_56: 0.9259\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3539 - siamese_loss: 4.6215 - mlp_loss: 0.3539 - mlp_binary_accuracy: 0.8380 - mlp_auc_56: 0.9219\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3588 - siamese_loss: 5.1091 - mlp_loss: 0.3588 - mlp_binary_accuracy: 0.8350 - mlp_auc_56: 0.9196\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3504 - siamese_loss: 5.0565 - mlp_loss: 0.3504 - mlp_binary_accuracy: 0.8365 - mlp_auc_56: 0.9230\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4457 - siamese_loss: 4.3110 - mlp_loss: 0.4457 - mlp_binary_accuracy: 0.8009 - mlp_auc_56: 0.8874\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4909 - siamese_loss: 4.5951 - mlp_loss: 0.4909 - mlp_binary_accuracy: 0.7842 - mlp_auc_56: 0.8705\n",
      "验证集十折------ mlp_binary_accuracy: 80.09%\t ----- mlp_auc_56: 88.74% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 78.42%\t ----- mlp_auc_56: 87.05% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 2 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6863 - siamese_loss: 2.9923 - mlp_loss: 0.6863 - mlp_binary_accuracy: 0.5700 - mlp_auc_57: 0.5970\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6450 - siamese_loss: 3.1649 - mlp_loss: 0.6450 - mlp_binary_accuracy: 0.6511 - mlp_auc_57: 0.6866\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6120 - siamese_loss: 3.5073 - mlp_loss: 0.6120 - mlp_binary_accuracy: 0.6710 - mlp_auc_57: 0.72 - 0s 2ms/step - loss: 0.6122 - siamese_loss: 3.5253 - mlp_loss: 0.6122 - mlp_binary_accuracy: 0.6703 - mlp_auc_57: 0.7284\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5997 - siamese_loss: 3.3871 - mlp_loss: 0.5997 - mlp_binary_accuracy: 0.6829 - mlp_auc_57: 0.7440\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5897 - siamese_loss: 3.0962 - mlp_loss: 0.5897 - mlp_binary_accuracy: 0.7028 - mlp_auc_57: 0.7531\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5725 - siamese_loss: 3.3354 - mlp_loss: 0.5725 - mlp_binary_accuracy: 0.7161 - mlp_auc_57: 0.7723\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5636 - siamese_loss: 3.1829 - mlp_loss: 0.5636 - mlp_binary_accuracy: 0.7237 - mlp_auc_57: 0.7807\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5534 - siamese_loss: 3.2229 - mlp_loss: 0.5534 - mlp_binary_accuracy: 0.7227 - mlp_auc_57: 0.7917\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5457 - siamese_loss: 3.3737 - mlp_loss: 0.5457 - mlp_binary_accuracy: 0.7257 - mlp_auc_57: 0.7993\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5442 - siamese_loss: 2.8013 - mlp_loss: 0.5442 - mlp_binary_accuracy: 0.7320 - mlp_auc_57: 0.7998\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.5260 - siamese_loss: 3.0159 - mlp_loss: 0.5260 - mlp_binary_accuracy: 0.7423 - mlp_auc_57: 0.8164\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5096 - siamese_loss: 2.8278 - mlp_loss: 0.5096 - mlp_binary_accuracy: 0.7564 - mlp_auc_57: 0.8292\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5041 - siamese_loss: 3.1624 - mlp_loss: 0.5041 - mlp_binary_accuracy: 0.7625 - mlp_auc_57: 0.8334\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4955 - siamese_loss: 2.8160 - mlp_loss: 0.4955 - mlp_binary_accuracy: 0.7713 - mlp_auc_57: 0.8397\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4878 - siamese_loss: 2.4997 - mlp_loss: 0.4878 - mlp_binary_accuracy: 0.7768 - mlp_auc_57: 0.8452\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4824 - siamese_loss: 2.2857 - mlp_loss: 0.4824 - mlp_binary_accuracy: 0.7783 - mlp_auc_57: 0.8495\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4708 - siamese_loss: 2.5428 - mlp_loss: 0.4708 - mlp_binary_accuracy: 0.7866 - mlp_auc_57: 0.8580\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4683 - siamese_loss: 2.7916 - mlp_loss: 0.4683 - mlp_binary_accuracy: 0.7824 - mlp_auc_57: 0.8597\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4686 - siamese_loss: 3.0085 - mlp_loss: 0.4686 - mlp_binary_accuracy: 0.7864 - mlp_auc_57: 0.8594\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4582 - siamese_loss: 3.1829 - mlp_loss: 0.4582 - mlp_binary_accuracy: 0.7892 - mlp_auc_57: 0.8661\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4500 - siamese_loss: 3.2751 - mlp_loss: 0.4500 - mlp_binary_accuracy: 0.7877 - mlp_auc_57: 0.8705\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4540 - siamese_loss: 3.2584 - mlp_loss: 0.4540 - mlp_binary_accuracy: 0.7877 - mlp_auc_57: 0.8686\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4476 - siamese_loss: 3.4222 - mlp_loss: 0.4476 - mlp_binary_accuracy: 0.7922 - mlp_auc_57: 0.8726\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4530 - siamese_loss: 2.8612 - mlp_loss: 0.4530 - mlp_binary_accuracy: 0.7897 - mlp_auc_57: 0.8685\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4556 - siamese_loss: 2.7757 - mlp_loss: 0.4556 - mlp_binary_accuracy: 0.7922 - mlp_auc_57: 0.8677\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4465 - siamese_loss: 3.0348 - mlp_loss: 0.4465 - mlp_binary_accuracy: 0.8003 - mlp_auc_57: 0.8728\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4347 - siamese_loss: 3.2769 - mlp_loss: 0.4347 - mlp_binary_accuracy: 0.8065 - mlp_auc_57: 0.8800\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4337 - siamese_loss: 3.3381 - mlp_loss: 0.4337 - mlp_binary_accuracy: 0.8023 - mlp_auc_57: 0.8808\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4244 - siamese_loss: 3.4777 - mlp_loss: 0.4244 - mlp_binary_accuracy: 0.8078 - mlp_auc_57: 0.8860\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4199 - siamese_loss: 3.7166 - mlp_loss: 0.4199 - mlp_binary_accuracy: 0.8111 - mlp_auc_57: 0.8886\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4211 - siamese_loss: 3.5515 - mlp_loss: 0.4211 - mlp_binary_accuracy: 0.8111 - mlp_auc_57: 0.8876\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4130 - siamese_loss: 3.5014 - mlp_loss: 0.4130 - mlp_binary_accuracy: 0.8106 - mlp_auc_57: 0.8923\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4142 - siamese_loss: 3.3514 - mlp_loss: 0.4142 - mlp_binary_accuracy: 0.8169 - mlp_auc_57: 0.8916\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4113 - siamese_loss: 3.6254 - mlp_loss: 0.4113 - mlp_binary_accuracy: 0.8171 - mlp_auc_57: 0.8933\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.4062 - siamese_loss: 3.7367 - mlp_loss: 0.4062 - mlp_binary_accuracy: 0.8179 - mlp_auc_57: 0.8963\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4038 - siamese_loss: 3.3613 - mlp_loss: 0.4038 - mlp_binary_accuracy: 0.8249 - mlp_auc_57: 0.8970\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4087 - siamese_loss: 3.3072 - mlp_loss: 0.4087 - mlp_binary_accuracy: 0.8212 - mlp_auc_57: 0.8941\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4022 - siamese_loss: 3.2078 - mlp_loss: 0.4022 - mlp_binary_accuracy: 0.8184 - mlp_auc_57: 0.8981\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3993 - siamese_loss: 3.6384 - mlp_loss: 0.3993 - mlp_binary_accuracy: 0.8254 - mlp_auc_57: 0.8995\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4026 - siamese_loss: 3.5740 - mlp_loss: 0.4026 - mlp_binary_accuracy: 0.8257 - mlp_auc_57: 0.8973\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3947 - siamese_loss: 3.7164 - mlp_loss: 0.3947 - mlp_binary_accuracy: 0.8267 - mlp_auc_57: 0.9022\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3848 - siamese_loss: 3.7098 - mlp_loss: 0.3848 - mlp_binary_accuracy: 0.8295 - mlp_auc_57: 0.9078\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3904 - siamese_loss: 3.3017 - mlp_loss: 0.3904 - mlp_binary_accuracy: 0.8280 - mlp_auc_57: 0.9036\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3931 - siamese_loss: 3.0983 - mlp_loss: 0.3931 - mlp_binary_accuracy: 0.8272 - mlp_auc_57: 0.9020\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3921 - siamese_loss: 2.8164 - mlp_loss: 0.3921 - mlp_binary_accuracy: 0.8217 - mlp_auc_57: 0.9029\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3896 - siamese_loss: 2.4588 - mlp_loss: 0.3896 - mlp_binary_accuracy: 0.8282 - mlp_auc_57: 0.9034\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3834 - siamese_loss: 2.8291 - mlp_loss: 0.3834 - mlp_binary_accuracy: 0.8327 - mlp_auc_57: 0.9081\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3826 - siamese_loss: 3.1217 - mlp_loss: 0.3826 - mlp_binary_accuracy: 0.8343 - mlp_auc_57: 0.9076\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3823 - siamese_loss: 3.4572 - mlp_loss: 0.3823 - mlp_binary_accuracy: 0.8365 - mlp_auc_57: 0.9072\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3767 - siamese_loss: 3.6113 - mlp_loss: 0.3767 - mlp_binary_accuracy: 0.8350 - mlp_auc_57: 0.9106\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3763 - siamese_loss: 3.4276 - mlp_loss: 0.3763 - mlp_binary_accuracy: 0.8368 - mlp_auc_57: 0.9114\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3753 - siamese_loss: 3.1067 - mlp_loss: 0.3753 - mlp_binary_accuracy: 0.8398 - mlp_auc_57: 0.9112\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3665 - siamese_loss: 3.3937 - mlp_loss: 0.3665 - mlp_binary_accuracy: 0.8421 - mlp_auc_57: 0.9156\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3601 - siamese_loss: 3.5306 - mlp_loss: 0.3601 - mlp_binary_accuracy: 0.8421 - mlp_auc_57: 0.9190\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3649 - siamese_loss: 3.2886 - mlp_loss: 0.3649 - mlp_binary_accuracy: 0.8368 - mlp_auc_57: 0.9170\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3641 - siamese_loss: 3.6271 - mlp_loss: 0.3641 - mlp_binary_accuracy: 0.8365 - mlp_auc_57: 0.9174\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3591 - siamese_loss: 3.5719 - mlp_loss: 0.3591 - mlp_binary_accuracy: 0.8451 - mlp_auc_57: 0.9188\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3597 - siamese_loss: 3.5384 - mlp_loss: 0.3597 - mlp_binary_accuracy: 0.8426 - mlp_auc_57: 0.9190\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3608 - siamese_loss: 3.1518 - mlp_loss: 0.3608 - mlp_binary_accuracy: 0.8408 - mlp_auc_57: 0.9177\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3671 - siamese_loss: 3.3563 - mlp_loss: 0.3671 - mlp_binary_accuracy: 0.8393 - mlp_auc_57: 0.9158\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3516 - siamese_loss: 3.6103 - mlp_loss: 0.3516 - mlp_binary_accuracy: 0.8511 - mlp_auc_57: 0.9219\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3622 - siamese_loss: 3.3721 - mlp_loss: 0.3622 - mlp_binary_accuracy: 0.8423 - mlp_auc_57: 0.9175\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3700 - siamese_loss: 2.9729 - mlp_loss: 0.3700 - mlp_binary_accuracy: 0.8398 - mlp_auc_57: 0.9141\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3554 - siamese_loss: 3.7144 - mlp_loss: 0.3554 - mlp_binary_accuracy: 0.8446 - mlp_auc_57: 0.9209\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3456 - siamese_loss: 3.7267 - mlp_loss: 0.3456 - mlp_binary_accuracy: 0.8509 - mlp_auc_57: 0.9245\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3449 - siamese_loss: 3.4619 - mlp_loss: 0.3449 - mlp_binary_accuracy: 0.8521 - mlp_auc_57: 0.9249\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3527 - siamese_loss: 3.3584 - mlp_loss: 0.3527 - mlp_binary_accuracy: 0.8491 - mlp_auc_57: 0.9217\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3515 - siamese_loss: 3.7298 - mlp_loss: 0.3515 - mlp_binary_accuracy: 0.8484 - mlp_auc_57: 0.9233\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3620 - siamese_loss: 4.3295 - mlp_loss: 0.3620 - mlp_binary_accuracy: 0.8421 - mlp_auc_57: 0.9178\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3527 - siamese_loss: 4.3940 - mlp_loss: 0.3527 - mlp_binary_accuracy: 0.8514 - mlp_auc_57: 0.9224\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3483 - siamese_loss: 4.5124 - mlp_loss: 0.3483 - mlp_binary_accuracy: 0.8552 - mlp_auc_57: 0.9239\n",
      "14/14 [==============================] - 0s 514us/step - loss: 0.5307 - siamese_loss: 3.8457 - mlp_loss: 0.5307 - mlp_binary_accuracy: 0.7868 - mlp_auc_57: 0.8471\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4763 - siamese_loss: 3.8871 - mlp_loss: 0.4763 - mlp_binary_accuracy: 0.7879 - mlp_auc_57: 0.8721\n",
      "验证集十折------ mlp_binary_accuracy: 78.68%\t ----- mlp_auc_57: 84.71% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 78.79%\t ----- mlp_auc_57: 87.21% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 3 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6741 - siamese_loss: 4.0383 - mlp_loss: 0.6741 - mlp_binary_accuracy: 0.5756 - mlp_auc_58: 0.6156\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6395 - siamese_loss: 3.6204 - mlp_loss: 0.6395 - mlp_binary_accuracy: 0.6469 - mlp_auc_58: 0.6844\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6186 - siamese_loss: 3.6070 - mlp_loss: 0.6186 - mlp_binary_accuracy: 0.6610 - mlp_auc_58: 0.7141\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6078 - siamese_loss: 3.0583 - mlp_loss: 0.6078 - mlp_binary_accuracy: 0.6788 - mlp_auc_58: 0.7275\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5968 - siamese_loss: 2.8141 - mlp_loss: 0.5968 - mlp_binary_accuracy: 0.6811 - mlp_auc_58: 0.7416\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5871 - siamese_loss: 2.8824 - mlp_loss: 0.5871 - mlp_binary_accuracy: 0.6955 - mlp_auc_58: 0.7566\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5717 - siamese_loss: 3.2888 - mlp_loss: 0.5717 - mlp_binary_accuracy: 0.7103 - mlp_auc_58: 0.7731\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5615 - siamese_loss: 3.6513 - mlp_loss: 0.5615 - mlp_binary_accuracy: 0.7149 - mlp_auc_58: 0.7837\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5517 - siamese_loss: 3.6058 - mlp_loss: 0.5517 - mlp_binary_accuracy: 0.7252 - mlp_auc_58: 0.7926\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5342 - siamese_loss: 3.6359 - mlp_loss: 0.5342 - mlp_binary_accuracy: 0.7403 - mlp_auc_58: 0.8084\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5270 - siamese_loss: 3.3999 - mlp_loss: 0.5270 - mlp_binary_accuracy: 0.7421 - mlp_auc_58: 0.8140\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5030 - siamese_loss: 3.2549 - mlp_loss: 0.5030 - mlp_binary_accuracy: 0.7579 - mlp_auc_58: 0.8338\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4915 - siamese_loss: 3.4352 - mlp_loss: 0.4915 - mlp_binary_accuracy: 0.7645 - mlp_auc_58: 0.8423\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4832 - siamese_loss: 3.5413 - mlp_loss: 0.4832 - mlp_binary_accuracy: 0.7738 - mlp_auc_58: 0.8484\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4640 - siamese_loss: 3.4236 - mlp_loss: 0.4640 - mlp_binary_accuracy: 0.7824 - mlp_auc_58: 0.8612\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4533 - siamese_loss: 3.4328 - mlp_loss: 0.4533 - mlp_binary_accuracy: 0.7882 - mlp_auc_58: 0.8680\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4470 - siamese_loss: 3.3969 - mlp_loss: 0.4470 - mlp_binary_accuracy: 0.7985 - mlp_auc_58: 0.8717\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4446 - siamese_loss: 3.3482 - mlp_loss: 0.4446 - mlp_binary_accuracy: 0.7892 - mlp_auc_58: 0.8736\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4395 - siamese_loss: 3.6092 - mlp_loss: 0.4395 - mlp_binary_accuracy: 0.7992 - mlp_auc_58: 0.8770\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4415 - siamese_loss: 3.7719 - mlp_loss: 0.4415 - mlp_binary_accuracy: 0.7975 - mlp_auc_58: 0.8759\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4289 - siamese_loss: 3.6329 - mlp_loss: 0.4289 - mlp_binary_accuracy: 0.8098 - mlp_auc_58: 0.8831\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4254 - siamese_loss: 3.2997 - mlp_loss: 0.4254 - mlp_binary_accuracy: 0.8128 - mlp_auc_58: 0.8844\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4325 - siamese_loss: 3.5358 - mlp_loss: 0.4325 - mlp_binary_accuracy: 0.8058 - mlp_auc_58: 0.8799\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4346 - siamese_loss: 2.9336 - mlp_loss: 0.4346 - mlp_binary_accuracy: 0.8023 - mlp_auc_58: 0.8787\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4158 - siamese_loss: 3.4386 - mlp_loss: 0.4158 - mlp_binary_accuracy: 0.8086 - mlp_auc_58: 0.8897\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4234 - siamese_loss: 3.2218 - mlp_loss: 0.4234 - mlp_binary_accuracy: 0.8098 - mlp_auc_58: 0.8854\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4079 - siamese_loss: 3.3683 - mlp_loss: 0.4079 - mlp_binary_accuracy: 0.8149 - mlp_auc_58: 0.8946\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4053 - siamese_loss: 3.6281 - mlp_loss: 0.4053 - mlp_binary_accuracy: 0.8227 - mlp_auc_58: 0.8949\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4048 - siamese_loss: 3.7414 - mlp_loss: 0.4048 - mlp_binary_accuracy: 0.8229 - mlp_auc_58: 0.8958\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4029 - siamese_loss: 3.6266 - mlp_loss: 0.4029 - mlp_binary_accuracy: 0.8259 - mlp_auc_58: 0.8969\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4133 - siamese_loss: 3.6591 - mlp_loss: 0.4133 - mlp_binary_accuracy: 0.8136 - mlp_auc_58: 0.8921\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4142 - siamese_loss: 3.9010 - mlp_loss: 0.4142 - mlp_binary_accuracy: 0.8196 - mlp_auc_58: 0.8910\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4058 - siamese_loss: 3.9655 - mlp_loss: 0.4058 - mlp_binary_accuracy: 0.8219 - mlp_auc_58: 0.8946\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4022 - siamese_loss: 3.8412 - mlp_loss: 0.4022 - mlp_binary_accuracy: 0.8217 - mlp_auc_58: 0.8975\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3952 - siamese_loss: 3.4232 - mlp_loss: 0.3952 - mlp_binary_accuracy: 0.8262 - mlp_auc_58: 0.9015\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4041 - siamese_loss: 3.5730 - mlp_loss: 0.4041 - mlp_binary_accuracy: 0.8207 - mlp_auc_58: 0.8967\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4010 - siamese_loss: 3.4194 - mlp_loss: 0.4010 - mlp_binary_accuracy: 0.8217 - mlp_auc_58: 0.8983\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3835 - siamese_loss: 3.6567 - mlp_loss: 0.3835 - mlp_binary_accuracy: 0.8295 - mlp_auc_58: 0.9068\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3934 - siamese_loss: 3.7960 - mlp_loss: 0.3934 - mlp_binary_accuracy: 0.8247 - mlp_auc_58: 0.9015\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3894 - siamese_loss: 3.7282 - mlp_loss: 0.3894 - mlp_binary_accuracy: 0.8287 - mlp_auc_58: 0.9040\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3779 - siamese_loss: 4.1842 - mlp_loss: 0.3779 - mlp_binary_accuracy: 0.8322 - mlp_auc_58: 0.9092\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3813 - siamese_loss: 4.3185 - mlp_loss: 0.3813 - mlp_binary_accuracy: 0.8340 - mlp_auc_58: 0.9072\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3667 - siamese_loss: 4.1867 - mlp_loss: 0.3667 - mlp_binary_accuracy: 0.8426 - mlp_auc_58: 0.9148\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3735 - siamese_loss: 4.0833 - mlp_loss: 0.3735 - mlp_binary_accuracy: 0.8406 - mlp_auc_58: 0.9124\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.3639 - siamese_loss: 4.0624 - mlp_loss: 0.3639 - mlp_binary_accuracy: 0.8428 - mlp_auc_58: 0.91 - 0s 2ms/step - loss: 0.3666 - siamese_loss: 4.0437 - mlp_loss: 0.3666 - mlp_binary_accuracy: 0.8390 - mlp_auc_58: 0.9147\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3685 - siamese_loss: 3.9371 - mlp_loss: 0.3685 - mlp_binary_accuracy: 0.8401 - mlp_auc_58: 0.9141\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3749 - siamese_loss: 3.5121 - mlp_loss: 0.3749 - mlp_binary_accuracy: 0.8360 - mlp_auc_58: 0.9108\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3676 - siamese_loss: 3.3009 - mlp_loss: 0.3676 - mlp_binary_accuracy: 0.8393 - mlp_auc_58: 0.9139\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3692 - siamese_loss: 4.1987 - mlp_loss: 0.3692 - mlp_binary_accuracy: 0.8343 - mlp_auc_58: 0.9139\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3600 - siamese_loss: 4.4224 - mlp_loss: 0.3600 - mlp_binary_accuracy: 0.8411 - mlp_auc_58: 0.9178\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3669 - siamese_loss: 3.7862 - mlp_loss: 0.3669 - mlp_binary_accuracy: 0.8380 - mlp_auc_58: 0.9147\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3691 - siamese_loss: 3.9264 - mlp_loss: 0.3691 - mlp_binary_accuracy: 0.8378 - mlp_auc_58: 0.9129\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3585 - siamese_loss: 4.1902 - mlp_loss: 0.3585 - mlp_binary_accuracy: 0.8413 - mlp_auc_58: 0.9184\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3611 - siamese_loss: 4.1351 - mlp_loss: 0.3611 - mlp_binary_accuracy: 0.8453 - mlp_auc_58: 0.9175\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3506 - siamese_loss: 4.2489 - mlp_loss: 0.3506 - mlp_binary_accuracy: 0.8458 - mlp_auc_58: 0.9231\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3620 - siamese_loss: 4.7063 - mlp_loss: 0.3620 - mlp_binary_accuracy: 0.8443 - mlp_auc_58: 0.9180\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3710 - siamese_loss: 5.1630 - mlp_loss: 0.3710 - mlp_binary_accuracy: 0.8373 - mlp_auc_58: 0.9137\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3564 - siamese_loss: 5.0742 - mlp_loss: 0.3564 - mlp_binary_accuracy: 0.8426 - mlp_auc_58: 0.9197\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3549 - siamese_loss: 4.9360 - mlp_loss: 0.3549 - mlp_binary_accuracy: 0.8456 - mlp_auc_58: 0.9215\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3525 - siamese_loss: 4.5213 - mlp_loss: 0.3525 - mlp_binary_accuracy: 0.8463 - mlp_auc_58: 0.9222\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5214 - siamese_loss: 4.7288 - mlp_loss: 0.5214 - mlp_binary_accuracy: 0.7687 - mlp_auc_58: 0.8636\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5222 - siamese_loss: 4.5914 - mlp_loss: 0.5222 - mlp_binary_accuracy: 0.7570 - mlp_auc_58: 0.8588\n",
      "验证集十折------ mlp_binary_accuracy: 76.87%\t ----- mlp_auc_58: 86.36% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 75.70%\t ----- mlp_auc_58: 85.88% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 4 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6790 - siamese_loss: 3.4126 - mlp_loss: 0.6790 - mlp_binary_accuracy: 0.5531 - mlp_auc_59: 0.5925\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6418 - siamese_loss: 3.3564 - mlp_loss: 0.6418 - mlp_binary_accuracy: 0.6282 - mlp_auc_59: 0.6789\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6114 - siamese_loss: 3.6469 - mlp_loss: 0.6114 - mlp_binary_accuracy: 0.6635 - mlp_auc_59: 0.7245\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.5990 - siamese_loss: 3.4531 - mlp_loss: 0.5990 - mlp_binary_accuracy: 0.6819 - mlp_auc_59: 0.7426\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5806 - siamese_loss: 3.1956 - mlp_loss: 0.5806 - mlp_binary_accuracy: 0.6960 - mlp_auc_59: 0.7636\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5635 - siamese_loss: 3.3319 - mlp_loss: 0.5635 - mlp_binary_accuracy: 0.7116 - mlp_auc_59: 0.7804\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5497 - siamese_loss: 3.4310 - mlp_loss: 0.5497 - mlp_binary_accuracy: 0.7282 - mlp_auc_59: 0.7926\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5386 - siamese_loss: 3.5068 - mlp_loss: 0.5386 - mlp_binary_accuracy: 0.7395 - mlp_auc_59: 0.8043\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5285 - siamese_loss: 3.2858 - mlp_loss: 0.5285 - mlp_binary_accuracy: 0.7438 - mlp_auc_59: 0.8140\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5136 - siamese_loss: 3.3030 - mlp_loss: 0.5136 - mlp_binary_accuracy: 0.7416 - mlp_auc_59: 0.8259\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5105 - siamese_loss: 3.0332 - mlp_loss: 0.5105 - mlp_binary_accuracy: 0.7564 - mlp_auc_59: 0.8295\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5004 - siamese_loss: 2.8134 - mlp_loss: 0.5004 - mlp_binary_accuracy: 0.7569 - mlp_auc_59: 0.8356\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4908 - siamese_loss: 2.6002 - mlp_loss: 0.4908 - mlp_binary_accuracy: 0.7705 - mlp_auc_59: 0.8423\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4857 - siamese_loss: 2.6487 - mlp_loss: 0.4857 - mlp_binary_accuracy: 0.7720 - mlp_auc_59: 0.8468\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4841 - siamese_loss: 2.6040 - mlp_loss: 0.4841 - mlp_binary_accuracy: 0.7741 - mlp_auc_59: 0.8482\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4743 - siamese_loss: 3.2339 - mlp_loss: 0.4743 - mlp_binary_accuracy: 0.7824 - mlp_auc_59: 0.8552\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4628 - siamese_loss: 3.3403 - mlp_loss: 0.4628 - mlp_binary_accuracy: 0.7899 - mlp_auc_59: 0.8629\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4460 - siamese_loss: 3.5971 - mlp_loss: 0.4460 - mlp_binary_accuracy: 0.7909 - mlp_auc_59: 0.8737\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4568 - siamese_loss: 3.6835 - mlp_loss: 0.4568 - mlp_binary_accuracy: 0.7864 - mlp_auc_59: 0.8654\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4526 - siamese_loss: 3.2503 - mlp_loss: 0.4526 - mlp_binary_accuracy: 0.7902 - mlp_auc_59: 0.8683\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4476 - siamese_loss: 3.2398 - mlp_loss: 0.4476 - mlp_binary_accuracy: 0.7907 - mlp_auc_59: 0.8710\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4410 - siamese_loss: 3.9120 - mlp_loss: 0.4410 - mlp_binary_accuracy: 0.8013 - mlp_auc_59: 0.8761\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4311 - siamese_loss: 3.7544 - mlp_loss: 0.4311 - mlp_binary_accuracy: 0.8033 - mlp_auc_59: 0.8828\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4350 - siamese_loss: 3.6591 - mlp_loss: 0.4350 - mlp_binary_accuracy: 0.7987 - mlp_auc_59: 0.8789\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4271 - siamese_loss: 3.7291 - mlp_loss: 0.4271 - mlp_binary_accuracy: 0.8096 - mlp_auc_59: 0.8833\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4211 - siamese_loss: 3.4707 - mlp_loss: 0.4211 - mlp_binary_accuracy: 0.8123 - mlp_auc_59: 0.8873\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4165 - siamese_loss: 3.9110 - mlp_loss: 0.4165 - mlp_binary_accuracy: 0.8103 - mlp_auc_59: 0.8913\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4204 - siamese_loss: 4.0557 - mlp_loss: 0.4204 - mlp_binary_accuracy: 0.8121 - mlp_auc_59: 0.8885\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4184 - siamese_loss: 3.7938 - mlp_loss: 0.4184 - mlp_binary_accuracy: 0.8126 - mlp_auc_59: 0.8893\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4069 - siamese_loss: 3.9146 - mlp_loss: 0.4069 - mlp_binary_accuracy: 0.8194 - mlp_auc_59: 0.8952\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3955 - siamese_loss: 4.3121 - mlp_loss: 0.3955 - mlp_binary_accuracy: 0.8272 - mlp_auc_59: 0.9010\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3850 - siamese_loss: 4.2978 - mlp_loss: 0.3850 - mlp_binary_accuracy: 0.8280 - mlp_auc_59: 0.9065\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3835 - siamese_loss: 4.2394 - mlp_loss: 0.3835 - mlp_binary_accuracy: 0.8340 - mlp_auc_59: 0.9078\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3906 - siamese_loss: 4.2300 - mlp_loss: 0.3906 - mlp_binary_accuracy: 0.8249 - mlp_auc_59: 0.9036\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3798 - siamese_loss: 4.3525 - mlp_loss: 0.3798 - mlp_binary_accuracy: 0.8307 - mlp_auc_59: 0.9091\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3831 - siamese_loss: 4.4206 - mlp_loss: 0.3831 - mlp_binary_accuracy: 0.8259 - mlp_auc_59: 0.9081\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3867 - siamese_loss: 4.2809 - mlp_loss: 0.3867 - mlp_binary_accuracy: 0.8272 - mlp_auc_59: 0.9065\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3820 - siamese_loss: 4.0933 - mlp_loss: 0.3820 - mlp_binary_accuracy: 0.8307 - mlp_auc_59: 0.9084\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3831 - siamese_loss: 4.2856 - mlp_loss: 0.3831 - mlp_binary_accuracy: 0.8320 - mlp_auc_59: 0.9081\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3734 - siamese_loss: 3.9806 - mlp_loss: 0.3734 - mlp_binary_accuracy: 0.8327 - mlp_auc_59: 0.9134\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3853 - siamese_loss: 4.1642 - mlp_loss: 0.3853 - mlp_binary_accuracy: 0.8280 - mlp_auc_59: 0.9062\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3776 - siamese_loss: 4.2548 - mlp_loss: 0.3776 - mlp_binary_accuracy: 0.8325 - mlp_auc_59: 0.9097\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3744 - siamese_loss: 4.2048 - mlp_loss: 0.3744 - mlp_binary_accuracy: 0.8390 - mlp_auc_59: 0.9113\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3755 - siamese_loss: 4.5203 - mlp_loss: 0.3755 - mlp_binary_accuracy: 0.8312 - mlp_auc_59: 0.9112\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3673 - siamese_loss: 4.3134 - mlp_loss: 0.3673 - mlp_binary_accuracy: 0.8368 - mlp_auc_59: 0.9146\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3602 - siamese_loss: 4.0806 - mlp_loss: 0.3602 - mlp_binary_accuracy: 0.8411 - mlp_auc_59: 0.9175\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3589 - siamese_loss: 4.2094 - mlp_loss: 0.3589 - mlp_binary_accuracy: 0.8378 - mlp_auc_59: 0.9199\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3459 - siamese_loss: 3.9632 - mlp_loss: 0.3459 - mlp_binary_accuracy: 0.8539 - mlp_auc_59: 0.9236\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3492 - siamese_loss: 3.9890 - mlp_loss: 0.3492 - mlp_binary_accuracy: 0.8413 - mlp_auc_59: 0.9228\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3498 - siamese_loss: 4.3380 - mlp_loss: 0.3498 - mlp_binary_accuracy: 0.8438 - mlp_auc_59: 0.9234\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3491 - siamese_loss: 4.3157 - mlp_loss: 0.3491 - mlp_binary_accuracy: 0.8436 - mlp_auc_59: 0.9226\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3446 - siamese_loss: 4.3452 - mlp_loss: 0.3446 - mlp_binary_accuracy: 0.8481 - mlp_auc_59: 0.9259\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3577 - siamese_loss: 4.4026 - mlp_loss: 0.3577 - mlp_binary_accuracy: 0.8436 - mlp_auc_59: 0.9198\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3390 - siamese_loss: 4.0133 - mlp_loss: 0.3390 - mlp_binary_accuracy: 0.8481 - mlp_auc_59: 0.9284\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3402 - siamese_loss: 4.2713 - mlp_loss: 0.3402 - mlp_binary_accuracy: 0.8486 - mlp_auc_59: 0.9277\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3389 - siamese_loss: 4.1572 - mlp_loss: 0.3389 - mlp_binary_accuracy: 0.8511 - mlp_auc_59: 0.9283\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3257 - siamese_loss: 4.2745 - mlp_loss: 0.3257 - mlp_binary_accuracy: 0.8605 - mlp_auc_59: 0.9336\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3305 - siamese_loss: 4.1105 - mlp_loss: 0.3305 - mlp_binary_accuracy: 0.8564 - mlp_auc_59: 0.9318\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3416 - siamese_loss: 3.8544 - mlp_loss: 0.3416 - mlp_binary_accuracy: 0.8494 - mlp_auc_59: 0.9259\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3272 - siamese_loss: 4.3915 - mlp_loss: 0.3272 - mlp_binary_accuracy: 0.8557 - mlp_auc_59: 0.9330\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3327 - siamese_loss: 4.3843 - mlp_loss: 0.3327 - mlp_binary_accuracy: 0.8531 - mlp_auc_59: 0.9305\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3461 - siamese_loss: 4.1626 - mlp_loss: 0.3461 - mlp_binary_accuracy: 0.8411 - mlp_auc_59: 0.9246\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4641 - siamese_loss: 3.1659 - mlp_loss: 0.4641 - mlp_binary_accuracy: 0.7800 - mlp_auc_59: 0.8813\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4637 - siamese_loss: 3.4772 - mlp_loss: 0.4637 - mlp_binary_accuracy: 0.7924 - mlp_auc_59: 0.8774\n",
      "验证集十折------ mlp_binary_accuracy: 78.00%\t ----- mlp_auc_59: 88.13% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 79.24%\t ----- mlp_auc_59: 87.74% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 5 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6816 - siamese_loss: 3.0046 - mlp_loss: 0.6816 - mlp_binary_accuracy: 0.5678 - mlp_auc_60: 0.6215\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6634 - siamese_loss: 3.5706 - mlp_loss: 0.6634 - mlp_binary_accuracy: 0.6365 - mlp_auc_60: 0.6800\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6376 - siamese_loss: 3.2776 - mlp_loss: 0.6376 - mlp_binary_accuracy: 0.6630 - mlp_auc_60: 0.7065\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6013 - siamese_loss: 3.7775 - mlp_loss: 0.6013 - mlp_binary_accuracy: 0.6741 - mlp_auc_60: 0.7348\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5828 - siamese_loss: 3.4907 - mlp_loss: 0.5828 - mlp_binary_accuracy: 0.6972 - mlp_auc_60: 0.7586\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5702 - siamese_loss: 3.4973 - mlp_loss: 0.5702 - mlp_binary_accuracy: 0.7013 - mlp_auc_60: 0.7694\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5490 - siamese_loss: 3.5909 - mlp_loss: 0.5490 - mlp_binary_accuracy: 0.7214 - mlp_auc_60: 0.7919\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5408 - siamese_loss: 3.8386 - mlp_loss: 0.5408 - mlp_binary_accuracy: 0.7290 - mlp_auc_60: 0.7996\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5313 - siamese_loss: 3.6197 - mlp_loss: 0.5313 - mlp_binary_accuracy: 0.7325 - mlp_auc_60: 0.8070\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5268 - siamese_loss: 3.1939 - mlp_loss: 0.5268 - mlp_binary_accuracy: 0.7370 - mlp_auc_60: 0.8102\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5239 - siamese_loss: 2.9252 - mlp_loss: 0.5239 - mlp_binary_accuracy: 0.7325 - mlp_auc_60: 0.8134\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5129 - siamese_loss: 3.0489 - mlp_loss: 0.5129 - mlp_binary_accuracy: 0.7446 - mlp_auc_60: 0.8225\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5001 - siamese_loss: 3.1312 - mlp_loss: 0.5001 - mlp_binary_accuracy: 0.7542 - mlp_auc_60: 0.8337\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4988 - siamese_loss: 2.9494 - mlp_loss: 0.4988 - mlp_binary_accuracy: 0.7549 - mlp_auc_60: 0.8344\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4976 - siamese_loss: 2.4464 - mlp_loss: 0.4976 - mlp_binary_accuracy: 0.7592 - mlp_auc_60: 0.8341\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4840 - siamese_loss: 2.3095 - mlp_loss: 0.4840 - mlp_binary_accuracy: 0.7635 - mlp_auc_60: 0.8446\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4727 - siamese_loss: 2.8756 - mlp_loss: 0.4727 - mlp_binary_accuracy: 0.7798 - mlp_auc_60: 0.8513\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4689 - siamese_loss: 2.5895 - mlp_loss: 0.4689 - mlp_binary_accuracy: 0.7804 - mlp_auc_60: 0.8565\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4619 - siamese_loss: 2.6691 - mlp_loss: 0.4619 - mlp_binary_accuracy: 0.7869 - mlp_auc_60: 0.8623\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4609 - siamese_loss: 2.5790 - mlp_loss: 0.4609 - mlp_binary_accuracy: 0.7866 - mlp_auc_60: 0.8627\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4604 - siamese_loss: 2.9712 - mlp_loss: 0.4604 - mlp_binary_accuracy: 0.7882 - mlp_auc_60: 0.8622\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4589 - siamese_loss: 3.3863 - mlp_loss: 0.4589 - mlp_binary_accuracy: 0.7814 - mlp_auc_60: 0.8637\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4468 - siamese_loss: 3.4424 - mlp_loss: 0.4468 - mlp_binary_accuracy: 0.7970 - mlp_auc_60: 0.8713\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4476 - siamese_loss: 2.6667 - mlp_loss: 0.4476 - mlp_binary_accuracy: 0.7935 - mlp_auc_60: 0.8711\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4487 - siamese_loss: 2.1758 - mlp_loss: 0.4487 - mlp_binary_accuracy: 0.7907 - mlp_auc_60: 0.8705\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4447 - siamese_loss: 2.9097 - mlp_loss: 0.4447 - mlp_binary_accuracy: 0.7975 - mlp_auc_60: 0.8729\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4278 - siamese_loss: 2.7635 - mlp_loss: 0.4278 - mlp_binary_accuracy: 0.8028 - mlp_auc_60: 0.8844\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4190 - siamese_loss: 2.8697 - mlp_loss: 0.4190 - mlp_binary_accuracy: 0.8055 - mlp_auc_60: 0.8876\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4132 - siamese_loss: 2.7023 - mlp_loss: 0.4132 - mlp_binary_accuracy: 0.8131 - mlp_auc_60: 0.8913\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4085 - siamese_loss: 2.6142 - mlp_loss: 0.4085 - mlp_binary_accuracy: 0.8118 - mlp_auc_60: 0.8930\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4197 - siamese_loss: 2.6601 - mlp_loss: 0.4197 - mlp_binary_accuracy: 0.8028 - mlp_auc_60: 0.8873\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4086 - siamese_loss: 3.0627 - mlp_loss: 0.4086 - mlp_binary_accuracy: 0.8118 - mlp_auc_60: 0.8927\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4005 - siamese_loss: 2.8517 - mlp_loss: 0.4005 - mlp_binary_accuracy: 0.8134 - mlp_auc_60: 0.8977\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4074 - siamese_loss: 2.5821 - mlp_loss: 0.4074 - mlp_binary_accuracy: 0.8156 - mlp_auc_60: 0.8944\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4080 - siamese_loss: 2.8219 - mlp_loss: 0.4080 - mlp_binary_accuracy: 0.8139 - mlp_auc_60: 0.8942\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3957 - siamese_loss: 2.6919 - mlp_loss: 0.3957 - mlp_binary_accuracy: 0.8209 - mlp_auc_60: 0.9001\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3944 - siamese_loss: 2.4161 - mlp_loss: 0.3944 - mlp_binary_accuracy: 0.8134 - mlp_auc_60: 0.9016\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3929 - siamese_loss: 2.5096 - mlp_loss: 0.3929 - mlp_binary_accuracy: 0.8179 - mlp_auc_60: 0.9017\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3816 - siamese_loss: 2.6691 - mlp_loss: 0.3816 - mlp_binary_accuracy: 0.8262 - mlp_auc_60: 0.9073\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3900 - siamese_loss: 2.7673 - mlp_loss: 0.3900 - mlp_binary_accuracy: 0.8159 - mlp_auc_60: 0.9031\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3968 - siamese_loss: 2.6947 - mlp_loss: 0.3968 - mlp_binary_accuracy: 0.8126 - mlp_auc_60: 0.9002\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3867 - siamese_loss: 2.4991 - mlp_loss: 0.3867 - mlp_binary_accuracy: 0.8209 - mlp_auc_60: 0.9043\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3874 - siamese_loss: 2.9722 - mlp_loss: 0.3874 - mlp_binary_accuracy: 0.8191 - mlp_auc_60: 0.9043\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3849 - siamese_loss: 3.0942 - mlp_loss: 0.3849 - mlp_binary_accuracy: 0.8242 - mlp_auc_60: 0.9048\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4362 - siamese_loss: 2.3534 - mlp_loss: 0.4362 - mlp_binary_accuracy: 0.8163 - mlp_auc_60: 0.8847\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4685 - siamese_loss: 2.5891 - mlp_loss: 0.4685 - mlp_binary_accuracy: 0.7897 - mlp_auc_60: 0.8704\n",
      "验证集十折------ mlp_binary_accuracy: 81.63%\t ----- mlp_auc_60: 88.47% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 78.97%\t ----- mlp_auc_60: 87.04% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 6 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6742 - siamese_loss: 4.3120 - mlp_loss: 0.6742 - mlp_binary_accuracy: 0.5791 - mlp_auc_61: 0.6137\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6481 - siamese_loss: 3.8283 - mlp_loss: 0.6481 - mlp_binary_accuracy: 0.6204 - mlp_auc_61: 0.6719\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6228 - siamese_loss: 3.1220 - mlp_loss: 0.6228 - mlp_binary_accuracy: 0.6519 - mlp_auc_61: 0.7105\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6020 - siamese_loss: 3.7354 - mlp_loss: 0.6020 - mlp_binary_accuracy: 0.6705 - mlp_auc_61: 0.7373\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5845 - siamese_loss: 3.6234 - mlp_loss: 0.5845 - mlp_binary_accuracy: 0.6872 - mlp_auc_61: 0.7580\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5795 - siamese_loss: 3.9086 - mlp_loss: 0.5795 - mlp_binary_accuracy: 0.6972 - mlp_auc_61: 0.7629\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5539 - siamese_loss: 3.5554 - mlp_loss: 0.5539 - mlp_binary_accuracy: 0.7053 - mlp_auc_61: 0.7877\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5306 - siamese_loss: 3.2415 - mlp_loss: 0.5306 - mlp_binary_accuracy: 0.7332 - mlp_auc_61: 0.8109\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5242 - siamese_loss: 3.4979 - mlp_loss: 0.5242 - mlp_binary_accuracy: 0.7355 - mlp_auc_61: 0.8148\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5116 - siamese_loss: 3.5815 - mlp_loss: 0.5116 - mlp_binary_accuracy: 0.7514 - mlp_auc_61: 0.8250\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5043 - siamese_loss: 3.8464 - mlp_loss: 0.5043 - mlp_binary_accuracy: 0.7557 - mlp_auc_61: 0.8308\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4949 - siamese_loss: 3.9556 - mlp_loss: 0.4949 - mlp_binary_accuracy: 0.7554 - mlp_auc_61: 0.8386\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4990 - siamese_loss: 3.4844 - mlp_loss: 0.4990 - mlp_binary_accuracy: 0.7506 - mlp_auc_61: 0.8351\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4858 - siamese_loss: 2.9014 - mlp_loss: 0.4858 - mlp_binary_accuracy: 0.7637 - mlp_auc_61: 0.8461\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4824 - siamese_loss: 3.1336 - mlp_loss: 0.4824 - mlp_binary_accuracy: 0.7688 - mlp_auc_61: 0.8484\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4735 - siamese_loss: 3.5963 - mlp_loss: 0.4735 - mlp_binary_accuracy: 0.7736 - mlp_auc_61: 0.8541\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4628 - siamese_loss: 4.2215 - mlp_loss: 0.4628 - mlp_binary_accuracy: 0.7761 - mlp_auc_61: 0.8609\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4670 - siamese_loss: 4.5670 - mlp_loss: 0.4670 - mlp_binary_accuracy: 0.7751 - mlp_auc_61: 0.8583\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4642 - siamese_loss: 4.4349 - mlp_loss: 0.4642 - mlp_binary_accuracy: 0.7811 - mlp_auc_61: 0.8589\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4542 - siamese_loss: 4.7570 - mlp_loss: 0.4542 - mlp_binary_accuracy: 0.7836 - mlp_auc_61: 0.8677\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4559 - siamese_loss: 4.2722 - mlp_loss: 0.4559 - mlp_binary_accuracy: 0.7836 - mlp_auc_61: 0.8657\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4406 - siamese_loss: 4.0585 - mlp_loss: 0.4406 - mlp_binary_accuracy: 0.8015 - mlp_auc_61: 0.8761\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4552 - siamese_loss: 3.8775 - mlp_loss: 0.4552 - mlp_binary_accuracy: 0.7809 - mlp_auc_61: 0.8656\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4371 - siamese_loss: 3.5792 - mlp_loss: 0.4371 - mlp_binary_accuracy: 0.7924 - mlp_auc_61: 0.8768\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4346 - siamese_loss: 3.0085 - mlp_loss: 0.4346 - mlp_binary_accuracy: 0.7982 - mlp_auc_61: 0.8786\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4321 - siamese_loss: 3.2829 - mlp_loss: 0.4321 - mlp_binary_accuracy: 0.7957 - mlp_auc_61: 0.8792\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4313 - siamese_loss: 3.0060 - mlp_loss: 0.4313 - mlp_binary_accuracy: 0.7945 - mlp_auc_61: 0.8810\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4343 - siamese_loss: 2.7470 - mlp_loss: 0.4343 - mlp_binary_accuracy: 0.7937 - mlp_auc_61: 0.8784\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4339 - siamese_loss: 2.8396 - mlp_loss: 0.4339 - mlp_binary_accuracy: 0.7985 - mlp_auc_61: 0.8795\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4248 - siamese_loss: 2.7616 - mlp_loss: 0.4248 - mlp_binary_accuracy: 0.7990 - mlp_auc_61: 0.8847\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4173 - siamese_loss: 3.3970 - mlp_loss: 0.4173 - mlp_binary_accuracy: 0.8058 - mlp_auc_61: 0.8886\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4123 - siamese_loss: 3.8506 - mlp_loss: 0.4123 - mlp_binary_accuracy: 0.8144 - mlp_auc_61: 0.8921\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4061 - siamese_loss: 3.5107 - mlp_loss: 0.4061 - mlp_binary_accuracy: 0.8118 - mlp_auc_61: 0.8952\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4048 - siamese_loss: 3.2898 - mlp_loss: 0.4048 - mlp_binary_accuracy: 0.8156 - mlp_auc_61: 0.8963\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4004 - siamese_loss: 3.7146 - mlp_loss: 0.4004 - mlp_binary_accuracy: 0.8156 - mlp_auc_61: 0.8981\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3946 - siamese_loss: 3.4758 - mlp_loss: 0.3946 - mlp_binary_accuracy: 0.8139 - mlp_auc_61: 0.9020\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3948 - siamese_loss: 3.6611 - mlp_loss: 0.3948 - mlp_binary_accuracy: 0.8214 - mlp_auc_61: 0.9017\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4000 - siamese_loss: 4.1704 - mlp_loss: 0.4000 - mlp_binary_accuracy: 0.8194 - mlp_auc_61: 0.9003\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3908 - siamese_loss: 4.0580 - mlp_loss: 0.3908 - mlp_binary_accuracy: 0.8161 - mlp_auc_61: 0.9041\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3909 - siamese_loss: 4.0633 - mlp_loss: 0.3909 - mlp_binary_accuracy: 0.8252 - mlp_auc_61: 0.9038\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3885 - siamese_loss: 4.0444 - mlp_loss: 0.3885 - mlp_binary_accuracy: 0.8262 - mlp_auc_61: 0.9052\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3790 - siamese_loss: 3.8630 - mlp_loss: 0.3790 - mlp_binary_accuracy: 0.8317 - mlp_auc_61: 0.9098\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3814 - siamese_loss: 3.8804 - mlp_loss: 0.3814 - mlp_binary_accuracy: 0.8277 - mlp_auc_61: 0.9083\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3849 - siamese_loss: 3.7223 - mlp_loss: 0.3849 - mlp_binary_accuracy: 0.8267 - mlp_auc_61: 0.9066\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3833 - siamese_loss: 3.8394 - mlp_loss: 0.3833 - mlp_binary_accuracy: 0.8287 - mlp_auc_61: 0.9076\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3747 - siamese_loss: 3.9053 - mlp_loss: 0.3747 - mlp_binary_accuracy: 0.8310 - mlp_auc_61: 0.9121\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3691 - siamese_loss: 3.8877 - mlp_loss: 0.3691 - mlp_binary_accuracy: 0.8385 - mlp_auc_61: 0.9150\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3825 - siamese_loss: 3.6281 - mlp_loss: 0.3825 - mlp_binary_accuracy: 0.8209 - mlp_auc_61: 0.9083\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3811 - siamese_loss: 3.0095 - mlp_loss: 0.3811 - mlp_binary_accuracy: 0.8191 - mlp_auc_61: 0.9085\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3831 - siamese_loss: 2.7671 - mlp_loss: 0.3831 - mlp_binary_accuracy: 0.8254 - mlp_auc_61: 0.9072\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3762 - siamese_loss: 3.7451 - mlp_loss: 0.3762 - mlp_binary_accuracy: 0.8280 - mlp_auc_61: 0.9120\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3664 - siamese_loss: 3.5181 - mlp_loss: 0.3664 - mlp_binary_accuracy: 0.8406 - mlp_auc_61: 0.9163\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3684 - siamese_loss: 3.6730 - mlp_loss: 0.3684 - mlp_binary_accuracy: 0.8390 - mlp_auc_61: 0.9155\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3628 - siamese_loss: 3.9920 - mlp_loss: 0.3628 - mlp_binary_accuracy: 0.8398 - mlp_auc_61: 0.9169\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3602 - siamese_loss: 4.2221 - mlp_loss: 0.3602 - mlp_binary_accuracy: 0.8416 - mlp_auc_61: 0.9191\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3504 - siamese_loss: 4.1970 - mlp_loss: 0.3504 - mlp_binary_accuracy: 0.8418 - mlp_auc_61: 0.9231\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3504 - siamese_loss: 3.7955 - mlp_loss: 0.3504 - mlp_binary_accuracy: 0.8411 - mlp_auc_61: 0.9235\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3562 - siamese_loss: 3.8746 - mlp_loss: 0.3562 - mlp_binary_accuracy: 0.8385 - mlp_auc_61: 0.9209\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3434 - siamese_loss: 3.7041 - mlp_loss: 0.3434 - mlp_binary_accuracy: 0.8544 - mlp_auc_61: 0.9268\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3477 - siamese_loss: 3.6837 - mlp_loss: 0.3477 - mlp_binary_accuracy: 0.8466 - mlp_auc_61: 0.9246\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3478 - siamese_loss: 3.6268 - mlp_loss: 0.3478 - mlp_binary_accuracy: 0.8486 - mlp_auc_61: 0.9248\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3421 - siamese_loss: 3.9521 - mlp_loss: 0.3421 - mlp_binary_accuracy: 0.8443 - mlp_auc_61: 0.9270\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3297 - siamese_loss: 4.3043 - mlp_loss: 0.3297 - mlp_binary_accuracy: 0.8589 - mlp_auc_61: 0.9325\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3397 - siamese_loss: 4.1510 - mlp_loss: 0.3397 - mlp_binary_accuracy: 0.8486 - mlp_auc_61: 0.9282\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3342 - siamese_loss: 4.4405 - mlp_loss: 0.3342 - mlp_binary_accuracy: 0.8516 - mlp_auc_61: 0.9310\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3337 - siamese_loss: 4.6129 - mlp_loss: 0.3337 - mlp_binary_accuracy: 0.8531 - mlp_auc_61: 0.9316\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3344 - siamese_loss: 4.4157 - mlp_loss: 0.3344 - mlp_binary_accuracy: 0.8567 - mlp_auc_61: 0.9305\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3249 - siamese_loss: 4.7277 - mlp_loss: 0.3249 - mlp_binary_accuracy: 0.8597 - mlp_auc_61: 0.9344\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3291 - siamese_loss: 4.2443 - mlp_loss: 0.3291 - mlp_binary_accuracy: 0.8557 - mlp_auc_61: 0.9325\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3323 - siamese_loss: 3.9671 - mlp_loss: 0.3323 - mlp_binary_accuracy: 0.8547 - mlp_auc_61: 0.9308\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3294 - siamese_loss: 4.0855 - mlp_loss: 0.3294 - mlp_binary_accuracy: 0.8597 - mlp_auc_61: 0.9326\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3248 - siamese_loss: 4.5938 - mlp_loss: 0.3248 - mlp_binary_accuracy: 0.8587 - mlp_auc_61: 0.9344\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3260 - siamese_loss: 4.6046 - mlp_loss: 0.3260 - mlp_binary_accuracy: 0.8607 - mlp_auc_61: 0.9337\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3198 - siamese_loss: 4.5818 - mlp_loss: 0.3198 - mlp_binary_accuracy: 0.8645 - mlp_auc_61: 0.9368\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3230 - siamese_loss: 4.3645 - mlp_loss: 0.3230 - mlp_binary_accuracy: 0.8599 - mlp_auc_61: 0.9354\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3187 - siamese_loss: 4.0304 - mlp_loss: 0.3187 - mlp_binary_accuracy: 0.8569 - mlp_auc_61: 0.9368\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3216 - siamese_loss: 4.0184 - mlp_loss: 0.3216 - mlp_binary_accuracy: 0.8579 - mlp_auc_61: 0.9355\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3279 - siamese_loss: 4.1894 - mlp_loss: 0.3279 - mlp_binary_accuracy: 0.8542 - mlp_auc_61: 0.9333\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3320 - siamese_loss: 4.5130 - mlp_loss: 0.3320 - mlp_binary_accuracy: 0.8506 - mlp_auc_61: 0.9313\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3307 - siamese_loss: 4.9053 - mlp_loss: 0.3307 - mlp_binary_accuracy: 0.8542 - mlp_auc_61: 0.9323\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3246 - siamese_loss: 4.8655 - mlp_loss: 0.3246 - mlp_binary_accuracy: 0.8594 - mlp_auc_61: 0.9345\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5144 - siamese_loss: 4.3464 - mlp_loss: 0.5144 - mlp_binary_accuracy: 0.7959 - mlp_auc_61: 0.8611\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4798 - siamese_loss: 4.4563 - mlp_loss: 0.4798 - mlp_binary_accuracy: 0.8024 - mlp_auc_61: 0.8741\n",
      "验证集十折------ mlp_binary_accuracy: 79.59%\t ----- mlp_auc_61: 86.11% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 80.24%\t ----- mlp_auc_61: 87.41% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 7 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "  1/125 [..............................] - ETA: 0s - loss: 0.7199 - siamese_loss: 4.2111 - mlp_loss: 0.7199 - mlp_binary_accuracy: 0.5000 - mlp_auc_62: 0.3613WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6816 - siamese_loss: 4.1196 - mlp_loss: 0.6816 - mlp_binary_accuracy: 0.5645 - mlp_auc_62: 0.5954\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6390 - siamese_loss: 2.9662 - mlp_loss: 0.6390 - mlp_binary_accuracy: 0.6418 - mlp_auc_62: 0.6885\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6208 - siamese_loss: 2.0121 - mlp_loss: 0.6208 - mlp_binary_accuracy: 0.6612 - mlp_auc_62: 0.7136\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6082 - siamese_loss: 1.8392 - mlp_loss: 0.6082 - mlp_binary_accuracy: 0.6781 - mlp_auc_62: 0.7288\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5899 - siamese_loss: 1.6296 - mlp_loss: 0.5899 - mlp_binary_accuracy: 0.6899 - mlp_auc_62: 0.7512\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5724 - siamese_loss: 1.4656 - mlp_loss: 0.5724 - mlp_binary_accuracy: 0.7023 - mlp_auc_62: 0.7701\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5570 - siamese_loss: 1.4284 - mlp_loss: 0.5570 - mlp_binary_accuracy: 0.7209 - mlp_auc_62: 0.7841\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5479 - siamese_loss: 2.2297 - mlp_loss: 0.5479 - mlp_binary_accuracy: 0.7222 - mlp_auc_62: 0.7950\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5353 - siamese_loss: 2.2524 - mlp_loss: 0.5353 - mlp_binary_accuracy: 0.7360 - mlp_auc_62: 0.8067\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5200 - siamese_loss: 2.2874 - mlp_loss: 0.5200 - mlp_binary_accuracy: 0.7398 - mlp_auc_62: 0.8198\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5054 - siamese_loss: 1.9051 - mlp_loss: 0.5054 - mlp_binary_accuracy: 0.7511 - mlp_auc_62: 0.8320\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4929 - siamese_loss: 1.0568 - mlp_loss: 0.4929 - mlp_binary_accuracy: 0.7662 - mlp_auc_62: 0.8414\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4848 - siamese_loss: 1.2068 - mlp_loss: 0.4848 - mlp_binary_accuracy: 0.7723 - mlp_auc_62: 0.8476\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4816 - siamese_loss: 1.6746 - mlp_loss: 0.4816 - mlp_binary_accuracy: 0.7673 - mlp_auc_62: 0.8498\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4686 - siamese_loss: 1.5660 - mlp_loss: 0.4686 - mlp_binary_accuracy: 0.7796 - mlp_auc_62: 0.8584\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4582 - siamese_loss: 1.3497 - mlp_loss: 0.4582 - mlp_binary_accuracy: 0.7866 - mlp_auc_62: 0.8645\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4651 - siamese_loss: 2.3350 - mlp_loss: 0.4651 - mlp_binary_accuracy: 0.7844 - mlp_auc_62: 0.8610\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4813 - siamese_loss: 3.3701 - mlp_loss: 0.4813 - mlp_binary_accuracy: 0.7776 - mlp_auc_62: 0.8497\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4929 - siamese_loss: 3.0620 - mlp_loss: 0.4929 - mlp_binary_accuracy: 0.7637 - mlp_auc_62: 0.8412\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4985 - siamese_loss: 2.6603 - mlp_loss: 0.4985 - mlp_binary_accuracy: 0.7562 - mlp_auc_62: 0.8368\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4839 - siamese_loss: 2.5764 - mlp_loss: 0.4839 - mlp_binary_accuracy: 0.7730 - mlp_auc_62: 0.8479\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5690 - siamese_loss: 1.5965 - mlp_loss: 0.5690 - mlp_binary_accuracy: 0.7188 - mlp_auc_62: 0.8200\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5266 - siamese_loss: 1.4892 - mlp_loss: 0.5266 - mlp_binary_accuracy: 0.7416 - mlp_auc_62: 0.8374\n",
      "验证集十折------ mlp_binary_accuracy: 71.88%\t ----- mlp_auc_62: 82.00% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 74.16%\t ----- mlp_auc_62: 83.74% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 8 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6712 - siamese_loss: 3.0463 - mlp_loss: 0.6712 - mlp_binary_accuracy: 0.5826 - mlp_auc_63: 0.6189\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6307 - siamese_loss: 2.5083 - mlp_loss: 0.6307 - mlp_binary_accuracy: 0.6469 - mlp_auc_63: 0.6971\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6082 - siamese_loss: 2.1674 - mlp_loss: 0.6082 - mlp_binary_accuracy: 0.6811 - mlp_auc_63: 0.7285\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5934 - siamese_loss: 2.6213 - mlp_loss: 0.5934 - mlp_binary_accuracy: 0.6904 - mlp_auc_63: 0.7477\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5804 - siamese_loss: 2.7044 - mlp_loss: 0.5804 - mlp_binary_accuracy: 0.6980 - mlp_auc_63: 0.7627\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5738 - siamese_loss: 2.6342 - mlp_loss: 0.5738 - mlp_binary_accuracy: 0.6980 - mlp_auc_63: 0.7699\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5591 - siamese_loss: 2.7056 - mlp_loss: 0.5591 - mlp_binary_accuracy: 0.7103 - mlp_auc_63: 0.7850\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5515 - siamese_loss: 3.0244 - mlp_loss: 0.5515 - mlp_binary_accuracy: 0.7161 - mlp_auc_63: 0.7944\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5620 - siamese_loss: 3.2606 - mlp_loss: 0.5620 - mlp_binary_accuracy: 0.7063 - mlp_auc_63: 0.7823\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5464 - siamese_loss: 3.2938 - mlp_loss: 0.5464 - mlp_binary_accuracy: 0.7196 - mlp_auc_63: 0.7979\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5342 - siamese_loss: 2.7865 - mlp_loss: 0.5342 - mlp_binary_accuracy: 0.7295 - mlp_auc_63: 0.8084\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5237 - siamese_loss: 3.0031 - mlp_loss: 0.5237 - mlp_binary_accuracy: 0.7406 - mlp_auc_63: 0.8175\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5170 - siamese_loss: 3.4770 - mlp_loss: 0.5170 - mlp_binary_accuracy: 0.7416 - mlp_auc_63: 0.8220\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5052 - siamese_loss: 3.2885 - mlp_loss: 0.5052 - mlp_binary_accuracy: 0.7501 - mlp_auc_63: 0.8319\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4961 - siamese_loss: 3.2304 - mlp_loss: 0.4961 - mlp_binary_accuracy: 0.7627 - mlp_auc_63: 0.8392\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4942 - siamese_loss: 2.9109 - mlp_loss: 0.4942 - mlp_binary_accuracy: 0.7637 - mlp_auc_63: 0.8409\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4801 - siamese_loss: 2.9937 - mlp_loss: 0.4801 - mlp_binary_accuracy: 0.7730 - mlp_auc_63: 0.8508\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4782 - siamese_loss: 2.9118 - mlp_loss: 0.4782 - mlp_binary_accuracy: 0.7688 - mlp_auc_63: 0.8514\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4720 - siamese_loss: 3.2966 - mlp_loss: 0.4720 - mlp_binary_accuracy: 0.7753 - mlp_auc_63: 0.8554\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4790 - siamese_loss: 3.0599 - mlp_loss: 0.4790 - mlp_binary_accuracy: 0.7746 - mlp_auc_63: 0.8518\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4753 - siamese_loss: 3.2951 - mlp_loss: 0.4753 - mlp_binary_accuracy: 0.7788 - mlp_auc_63: 0.8535\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4729 - siamese_loss: 3.0851 - mlp_loss: 0.4729 - mlp_binary_accuracy: 0.7773 - mlp_auc_63: 0.8556\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4531 - siamese_loss: 3.0264 - mlp_loss: 0.4531 - mlp_binary_accuracy: 0.7909 - mlp_auc_63: 0.8685\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4524 - siamese_loss: 3.0642 - mlp_loss: 0.4524 - mlp_binary_accuracy: 0.7924 - mlp_auc_63: 0.8691\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4509 - siamese_loss: 2.9582 - mlp_loss: 0.4509 - mlp_binary_accuracy: 0.7962 - mlp_auc_63: 0.8707\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4455 - siamese_loss: 2.7095 - mlp_loss: 0.4455 - mlp_binary_accuracy: 0.7937 - mlp_auc_63: 0.8734\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4383 - siamese_loss: 3.1539 - mlp_loss: 0.4383 - mlp_binary_accuracy: 0.7972 - mlp_auc_63: 0.8775\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4378 - siamese_loss: 3.1225 - mlp_loss: 0.4378 - mlp_binary_accuracy: 0.7982 - mlp_auc_63: 0.8775\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4382 - siamese_loss: 3.6196 - mlp_loss: 0.4382 - mlp_binary_accuracy: 0.7924 - mlp_auc_63: 0.8772\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4307 - siamese_loss: 3.7208 - mlp_loss: 0.4307 - mlp_binary_accuracy: 0.7997 - mlp_auc_63: 0.8819\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4269 - siamese_loss: 3.8167 - mlp_loss: 0.4269 - mlp_binary_accuracy: 0.8065 - mlp_auc_63: 0.8845\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4251 - siamese_loss: 3.3677 - mlp_loss: 0.4251 - mlp_binary_accuracy: 0.8038 - mlp_auc_63: 0.8848\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4178 - siamese_loss: 3.5527 - mlp_loss: 0.4178 - mlp_binary_accuracy: 0.8086 - mlp_auc_63: 0.8895\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4059 - siamese_loss: 3.6545 - mlp_loss: 0.4059 - mlp_binary_accuracy: 0.8191 - mlp_auc_63: 0.8960\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4163 - siamese_loss: 3.2777 - mlp_loss: 0.4163 - mlp_binary_accuracy: 0.8116 - mlp_auc_63: 0.8903\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4179 - siamese_loss: 2.9418 - mlp_loss: 0.4179 - mlp_binary_accuracy: 0.8043 - mlp_auc_63: 0.8889\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4128 - siamese_loss: 3.1960 - mlp_loss: 0.4128 - mlp_binary_accuracy: 0.8108 - mlp_auc_63: 0.8921\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4045 - siamese_loss: 2.9712 - mlp_loss: 0.4045 - mlp_binary_accuracy: 0.8186 - mlp_auc_63: 0.8975\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4056 - siamese_loss: 2.6428 - mlp_loss: 0.4056 - mlp_binary_accuracy: 0.8179 - mlp_auc_63: 0.8954\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3955 - siamese_loss: 2.9839 - mlp_loss: 0.3955 - mlp_binary_accuracy: 0.8202 - mlp_auc_63: 0.9013\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3882 - siamese_loss: 2.9759 - mlp_loss: 0.3882 - mlp_binary_accuracy: 0.8227 - mlp_auc_63: 0.9056\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4022 - siamese_loss: 2.6548 - mlp_loss: 0.4022 - mlp_binary_accuracy: 0.8176 - mlp_auc_63: 0.8982\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3887 - siamese_loss: 3.4708 - mlp_loss: 0.3887 - mlp_binary_accuracy: 0.8254 - mlp_auc_63: 0.9057\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3828 - siamese_loss: 3.9517 - mlp_loss: 0.3828 - mlp_binary_accuracy: 0.8285 - mlp_auc_63: 0.9078\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3759 - siamese_loss: 3.6438 - mlp_loss: 0.3759 - mlp_binary_accuracy: 0.8340 - mlp_auc_63: 0.9116\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3769 - siamese_loss: 3.5119 - mlp_loss: 0.3769 - mlp_binary_accuracy: 0.8275 - mlp_auc_63: 0.9113\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3773 - siamese_loss: 3.6855 - mlp_loss: 0.3773 - mlp_binary_accuracy: 0.8277 - mlp_auc_63: 0.9105\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3810 - siamese_loss: 4.6664 - mlp_loss: 0.3810 - mlp_binary_accuracy: 0.8332 - mlp_auc_63: 0.9096\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3767 - siamese_loss: 5.0935 - mlp_loss: 0.3767 - mlp_binary_accuracy: 0.8335 - mlp_auc_63: 0.9111\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3718 - siamese_loss: 4.3543 - mlp_loss: 0.3718 - mlp_binary_accuracy: 0.8335 - mlp_auc_63: 0.9132\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3645 - siamese_loss: 4.4158 - mlp_loss: 0.3645 - mlp_binary_accuracy: 0.8406 - mlp_auc_63: 0.9169\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3583 - siamese_loss: 4.4391 - mlp_loss: 0.3583 - mlp_binary_accuracy: 0.8401 - mlp_auc_63: 0.9197\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3700 - siamese_loss: 4.8235 - mlp_loss: 0.3700 - mlp_binary_accuracy: 0.8350 - mlp_auc_63: 0.9148\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3588 - siamese_loss: 4.9961 - mlp_loss: 0.3588 - mlp_binary_accuracy: 0.8436 - mlp_auc_63: 0.9198\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3551 - siamese_loss: 4.7515 - mlp_loss: 0.3551 - mlp_binary_accuracy: 0.8446 - mlp_auc_63: 0.9216\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3535 - siamese_loss: 4.7898 - mlp_loss: 0.3535 - mlp_binary_accuracy: 0.8469 - mlp_auc_63: 0.9221\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3561 - siamese_loss: 4.7794 - mlp_loss: 0.3561 - mlp_binary_accuracy: 0.8463 - mlp_auc_63: 0.9212\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3624 - siamese_loss: 5.0044 - mlp_loss: 0.3624 - mlp_binary_accuracy: 0.8411 - mlp_auc_63: 0.9179\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3565 - siamese_loss: 5.1564 - mlp_loss: 0.3565 - mlp_binary_accuracy: 0.8481 - mlp_auc_63: 0.9209\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3540 - siamese_loss: 5.1061 - mlp_loss: 0.3540 - mlp_binary_accuracy: 0.8408 - mlp_auc_63: 0.9218\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3573 - siamese_loss: 4.9971 - mlp_loss: 0.3573 - mlp_binary_accuracy: 0.8448 - mlp_auc_63: 0.9204\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4587 - siamese_loss: 3.7931 - mlp_loss: 0.4587 - mlp_binary_accuracy: 0.8209 - mlp_auc_63: 0.8766\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4636 - siamese_loss: 4.7198 - mlp_loss: 0.4636 - mlp_binary_accuracy: 0.7987 - mlp_auc_63: 0.8713\n",
      "验证集十折------ mlp_binary_accuracy: 82.09%\t ----- mlp_auc_63: 87.66% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 79.87%\t ----- mlp_auc_63: 87.13% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 9 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6861 - siamese_loss: 3.8179 - mlp_loss: 0.6861 - mlp_binary_accuracy: 0.5519 - mlp_auc_64: 0.5744\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6511 - siamese_loss: 4.2208 - mlp_loss: 0.6511 - mlp_binary_accuracy: 0.6272 - mlp_auc_64: 0.6656\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6292 - siamese_loss: 3.6490 - mlp_loss: 0.6292 - mlp_binary_accuracy: 0.6481 - mlp_auc_64: 0.6975\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6162 - siamese_loss: 2.9790 - mlp_loss: 0.6162 - mlp_binary_accuracy: 0.6662 - mlp_auc_64: 0.7181\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6094 - siamese_loss: 2.2045 - mlp_loss: 0.6094 - mlp_binary_accuracy: 0.6690 - mlp_auc_64: 0.7276\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5920 - siamese_loss: 2.3719 - mlp_loss: 0.5920 - mlp_binary_accuracy: 0.6849 - mlp_auc_64: 0.7503\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5766 - siamese_loss: 2.5267 - mlp_loss: 0.5766 - mlp_binary_accuracy: 0.6957 - mlp_auc_64: 0.7685\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5622 - siamese_loss: 2.8471 - mlp_loss: 0.5622 - mlp_binary_accuracy: 0.7222 - mlp_auc_64: 0.7830\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5375 - siamese_loss: 2.8366 - mlp_loss: 0.5375 - mlp_binary_accuracy: 0.7428 - mlp_auc_64: 0.8065\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5344 - siamese_loss: 3.1685 - mlp_loss: 0.5344 - mlp_binary_accuracy: 0.7380 - mlp_auc_64: 0.8084\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5184 - siamese_loss: 4.0649 - mlp_loss: 0.5184 - mlp_binary_accuracy: 0.7519 - mlp_auc_64: 0.8224\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5153 - siamese_loss: 4.2457 - mlp_loss: 0.5153 - mlp_binary_accuracy: 0.7499 - mlp_auc_64: 0.8244\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5140 - siamese_loss: 4.2186 - mlp_loss: 0.5140 - mlp_binary_accuracy: 0.7506 - mlp_auc_64: 0.8255\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5000 - siamese_loss: 4.1259 - mlp_loss: 0.5000 - mlp_binary_accuracy: 0.7592 - mlp_auc_64: 0.8370\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4952 - siamese_loss: 3.7289 - mlp_loss: 0.4952 - mlp_binary_accuracy: 0.7625 - mlp_auc_64: 0.8402\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4849 - siamese_loss: 3.7358 - mlp_loss: 0.4849 - mlp_binary_accuracy: 0.7730 - mlp_auc_64: 0.8474\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4695 - siamese_loss: 3.7094 - mlp_loss: 0.4695 - mlp_binary_accuracy: 0.7872 - mlp_auc_64: 0.8583\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4694 - siamese_loss: 3.4413 - mlp_loss: 0.4694 - mlp_binary_accuracy: 0.7814 - mlp_auc_64: 0.8585\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4764 - siamese_loss: 3.1229 - mlp_loss: 0.4764 - mlp_binary_accuracy: 0.7773 - mlp_auc_64: 0.8533\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4672 - siamese_loss: 3.2388 - mlp_loss: 0.4672 - mlp_binary_accuracy: 0.7821 - mlp_auc_64: 0.8595\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4551 - siamese_loss: 3.1886 - mlp_loss: 0.4551 - mlp_binary_accuracy: 0.7882 - mlp_auc_64: 0.8671\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4522 - siamese_loss: 3.0548 - mlp_loss: 0.4522 - mlp_binary_accuracy: 0.7899 - mlp_auc_64: 0.8692\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4569 - siamese_loss: 3.3017 - mlp_loss: 0.4569 - mlp_binary_accuracy: 0.7884 - mlp_auc_64: 0.8665\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4442 - siamese_loss: 3.4751 - mlp_loss: 0.4442 - mlp_binary_accuracy: 0.7980 - mlp_auc_64: 0.8743\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4318 - siamese_loss: 3.8353 - mlp_loss: 0.4318 - mlp_binary_accuracy: 0.8025 - mlp_auc_64: 0.8815\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4252 - siamese_loss: 4.0448 - mlp_loss: 0.4252 - mlp_binary_accuracy: 0.8106 - mlp_auc_64: 0.8855\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4348 - siamese_loss: 3.8254 - mlp_loss: 0.4348 - mlp_binary_accuracy: 0.7982 - mlp_auc_64: 0.8792\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4352 - siamese_loss: 4.0423 - mlp_loss: 0.4352 - mlp_binary_accuracy: 0.7992 - mlp_auc_64: 0.8800\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4169 - siamese_loss: 3.4711 - mlp_loss: 0.4169 - mlp_binary_accuracy: 0.8181 - mlp_auc_64: 0.8895\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4210 - siamese_loss: 3.9162 - mlp_loss: 0.4210 - mlp_binary_accuracy: 0.8098 - mlp_auc_64: 0.8876\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4186 - siamese_loss: 4.1110 - mlp_loss: 0.4186 - mlp_binary_accuracy: 0.8096 - mlp_auc_64: 0.8898\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4130 - siamese_loss: 4.3826 - mlp_loss: 0.4130 - mlp_binary_accuracy: 0.8156 - mlp_auc_64: 0.8923\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4126 - siamese_loss: 4.4036 - mlp_loss: 0.4126 - mlp_binary_accuracy: 0.8189 - mlp_auc_64: 0.8928\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4048 - siamese_loss: 4.2391 - mlp_loss: 0.4048 - mlp_binary_accuracy: 0.8207 - mlp_auc_64: 0.8963\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4021 - siamese_loss: 4.4118 - mlp_loss: 0.4021 - mlp_binary_accuracy: 0.8317 - mlp_auc_64: 0.8976\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4027 - siamese_loss: 3.9483 - mlp_loss: 0.4027 - mlp_binary_accuracy: 0.8247 - mlp_auc_64: 0.8979\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3922 - siamese_loss: 3.8858 - mlp_loss: 0.3922 - mlp_binary_accuracy: 0.8219 - mlp_auc_64: 0.9033\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3914 - siamese_loss: 4.0167 - mlp_loss: 0.3914 - mlp_binary_accuracy: 0.8292 - mlp_auc_64: 0.9036\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3930 - siamese_loss: 4.0006 - mlp_loss: 0.3930 - mlp_binary_accuracy: 0.8264 - mlp_auc_64: 0.9024\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3910 - siamese_loss: 3.9100 - mlp_loss: 0.3910 - mlp_binary_accuracy: 0.8295 - mlp_auc_64: 0.9030\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3875 - siamese_loss: 4.1509 - mlp_loss: 0.3875 - mlp_binary_accuracy: 0.8262 - mlp_auc_64: 0.9062\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3876 - siamese_loss: 3.8956 - mlp_loss: 0.3876 - mlp_binary_accuracy: 0.8277 - mlp_auc_64: 0.9055\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3815 - siamese_loss: 4.1472 - mlp_loss: 0.3815 - mlp_binary_accuracy: 0.8292 - mlp_auc_64: 0.9086\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3767 - siamese_loss: 4.0478 - mlp_loss: 0.3767 - mlp_binary_accuracy: 0.8330 - mlp_auc_64: 0.9111\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3678 - siamese_loss: 4.0360 - mlp_loss: 0.3678 - mlp_binary_accuracy: 0.8401 - mlp_auc_64: 0.9152\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3719 - siamese_loss: 4.3154 - mlp_loss: 0.3719 - mlp_binary_accuracy: 0.8395 - mlp_auc_64: 0.9135\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3832 - siamese_loss: 4.3750 - mlp_loss: 0.3832 - mlp_binary_accuracy: 0.8335 - mlp_auc_64: 0.9071\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3683 - siamese_loss: 4.0991 - mlp_loss: 0.3683 - mlp_binary_accuracy: 0.8418 - mlp_auc_64: 0.9149\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3679 - siamese_loss: 4.1278 - mlp_loss: 0.3679 - mlp_binary_accuracy: 0.8363 - mlp_auc_64: 0.9151\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3746 - siamese_loss: 3.9667 - mlp_loss: 0.3746 - mlp_binary_accuracy: 0.8375 - mlp_auc_64: 0.9121\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3839 - siamese_loss: 3.7860 - mlp_loss: 0.3839 - mlp_binary_accuracy: 0.8231 - mlp_auc_64: 0.9089\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4731 - siamese_loss: 4.1020 - mlp_loss: 0.4731 - mlp_binary_accuracy: 0.7860 - mlp_auc_64: 0.8637\n",
      "验证集十折------ mlp_binary_accuracy: 82.31%\t ----- mlp_auc_64: 90.89% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 78.60%\t ----- mlp_auc_64: 86.37% \n",
      "\n",
      "concat_fea的shape： (None, 112)\n",
      "-------------------------------------Kfold: 10 iter-----------------------------------------\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6736 - siamese_loss: 4.2579 - mlp_loss: 0.6736 - mlp_binary_accuracy: 0.5809 - mlp_auc_65: 0.6134\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6386 - siamese_loss: 3.8368 - mlp_loss: 0.6386 - mlp_binary_accuracy: 0.6388 - mlp_auc_65: 0.6848\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6178 - siamese_loss: 3.4024 - mlp_loss: 0.6178 - mlp_binary_accuracy: 0.6680 - mlp_auc_65: 0.7214\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5962 - siamese_loss: 3.0172 - mlp_loss: 0.5962 - mlp_binary_accuracy: 0.6897 - mlp_auc_65: 0.7470\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6031 - siamese_loss: 2.7165 - mlp_loss: 0.6031 - mlp_binary_accuracy: 0.6793 - mlp_auc_65: 0.7377\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5837 - siamese_loss: 2.9644 - mlp_loss: 0.5837 - mlp_binary_accuracy: 0.7003 - mlp_auc_65: 0.7607\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5619 - siamese_loss: 3.1973 - mlp_loss: 0.5619 - mlp_binary_accuracy: 0.7184 - mlp_auc_65: 0.7839\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5474 - siamese_loss: 3.5162 - mlp_loss: 0.5474 - mlp_binary_accuracy: 0.7345 - mlp_auc_65: 0.7973\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5344 - siamese_loss: 3.8822 - mlp_loss: 0.5344 - mlp_binary_accuracy: 0.7395 - mlp_auc_65: 0.8094\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5216 - siamese_loss: 3.0864 - mlp_loss: 0.5216 - mlp_binary_accuracy: 0.7479 - mlp_auc_65: 0.8193\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5129 - siamese_loss: 3.7068 - mlp_loss: 0.5129 - mlp_binary_accuracy: 0.7557 - mlp_auc_65: 0.8265\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5097 - siamese_loss: 4.2365 - mlp_loss: 0.5097 - mlp_binary_accuracy: 0.7572 - mlp_auc_65: 0.8298\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5036 - siamese_loss: 3.9005 - mlp_loss: 0.5036 - mlp_binary_accuracy: 0.7635 - mlp_auc_65: 0.8337\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4801 - siamese_loss: 4.0707 - mlp_loss: 0.4801 - mlp_binary_accuracy: 0.7728 - mlp_auc_65: 0.8512\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4728 - siamese_loss: 3.8330 - mlp_loss: 0.4728 - mlp_binary_accuracy: 0.7887 - mlp_auc_65: 0.8559\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4691 - siamese_loss: 3.8384 - mlp_loss: 0.4691 - mlp_binary_accuracy: 0.7849 - mlp_auc_65: 0.8582\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4565 - siamese_loss: 3.3771 - mlp_loss: 0.4565 - mlp_binary_accuracy: 0.7904 - mlp_auc_65: 0.8663\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4546 - siamese_loss: 3.1717 - mlp_loss: 0.4546 - mlp_binary_accuracy: 0.7912 - mlp_auc_65: 0.8677\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4480 - siamese_loss: 3.3474 - mlp_loss: 0.4480 - mlp_binary_accuracy: 0.7937 - mlp_auc_65: 0.8723\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4496 - siamese_loss: 3.6454 - mlp_loss: 0.4496 - mlp_binary_accuracy: 0.7950 - mlp_auc_65: 0.8711\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4511 - siamese_loss: 3.8635 - mlp_loss: 0.4511 - mlp_binary_accuracy: 0.7929 - mlp_auc_65: 0.8693\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4515 - siamese_loss: 3.7745 - mlp_loss: 0.4515 - mlp_binary_accuracy: 0.7884 - mlp_auc_65: 0.8691\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4397 - siamese_loss: 3.6133 - mlp_loss: 0.4397 - mlp_binary_accuracy: 0.7962 - mlp_auc_65: 0.8763\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4381 - siamese_loss: 3.8865 - mlp_loss: 0.4381 - mlp_binary_accuracy: 0.7987 - mlp_auc_65: 0.8781\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4330 - siamese_loss: 3.6677 - mlp_loss: 0.4330 - mlp_binary_accuracy: 0.8068 - mlp_auc_65: 0.8807\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4332 - siamese_loss: 3.4160 - mlp_loss: 0.4332 - mlp_binary_accuracy: 0.7967 - mlp_auc_65: 0.8803\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4235 - siamese_loss: 3.7205 - mlp_loss: 0.4235 - mlp_binary_accuracy: 0.8040 - mlp_auc_65: 0.8859\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4268 - siamese_loss: 3.6708 - mlp_loss: 0.4268 - mlp_binary_accuracy: 0.8081 - mlp_auc_65: 0.8841\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4122 - siamese_loss: 3.9638 - mlp_loss: 0.4122 - mlp_binary_accuracy: 0.8169 - mlp_auc_65: 0.8923\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4113 - siamese_loss: 3.8158 - mlp_loss: 0.4113 - mlp_binary_accuracy: 0.8121 - mlp_auc_65: 0.8926\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4078 - siamese_loss: 3.9756 - mlp_loss: 0.4078 - mlp_binary_accuracy: 0.8131 - mlp_auc_65: 0.8951\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4069 - siamese_loss: 4.0821 - mlp_loss: 0.4069 - mlp_binary_accuracy: 0.8146 - mlp_auc_65: 0.8954\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4073 - siamese_loss: 3.8076 - mlp_loss: 0.4073 - mlp_binary_accuracy: 0.8116 - mlp_auc_65: 0.8955\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3999 - siamese_loss: 4.0169 - mlp_loss: 0.3999 - mlp_binary_accuracy: 0.8166 - mlp_auc_65: 0.8994\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4030 - siamese_loss: 4.1742 - mlp_loss: 0.4030 - mlp_binary_accuracy: 0.8156 - mlp_auc_65: 0.8967\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3964 - siamese_loss: 4.4621 - mlp_loss: 0.3964 - mlp_binary_accuracy: 0.8184 - mlp_auc_65: 0.9008\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4048 - siamese_loss: 4.5964 - mlp_loss: 0.4048 - mlp_binary_accuracy: 0.8151 - mlp_auc_65: 0.8964\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3994 - siamese_loss: 4.3499 - mlp_loss: 0.3994 - mlp_binary_accuracy: 0.8202 - mlp_auc_65: 0.8991\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3944 - siamese_loss: 4.6636 - mlp_loss: 0.3944 - mlp_binary_accuracy: 0.8237 - mlp_auc_65: 0.9018\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3893 - siamese_loss: 4.7963 - mlp_loss: 0.3893 - mlp_binary_accuracy: 0.8300 - mlp_auc_65: 0.9045\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3873 - siamese_loss: 4.8103 - mlp_loss: 0.3873 - mlp_binary_accuracy: 0.8229 - mlp_auc_65: 0.9055\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3950 - siamese_loss: 4.8541 - mlp_loss: 0.3950 - mlp_binary_accuracy: 0.8282 - mlp_auc_65: 0.9017\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3937 - siamese_loss: 4.5722 - mlp_loss: 0.3937 - mlp_binary_accuracy: 0.8184 - mlp_auc_65: 0.9025\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3811 - siamese_loss: 4.7143 - mlp_loss: 0.3811 - mlp_binary_accuracy: 0.8300 - mlp_auc_65: 0.9084\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3762 - siamese_loss: 5.0751 - mlp_loss: 0.3762 - mlp_binary_accuracy: 0.8330 - mlp_auc_65: 0.9108\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3784 - siamese_loss: 4.9017 - mlp_loss: 0.3784 - mlp_binary_accuracy: 0.8290 - mlp_auc_65: 0.9103\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3699 - siamese_loss: 4.8369 - mlp_loss: 0.3699 - mlp_binary_accuracy: 0.8373 - mlp_auc_65: 0.9137\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4031 - siamese_loss: 4.1382 - mlp_loss: 0.4031 - mlp_binary_accuracy: 0.8141 - mlp_auc_65: 0.8971\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4024 - siamese_loss: 3.5825 - mlp_loss: 0.4024 - mlp_binary_accuracy: 0.8103 - mlp_auc_65: 0.8975\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3872 - siamese_loss: 4.2868 - mlp_loss: 0.3872 - mlp_binary_accuracy: 0.8199 - mlp_auc_65: 0.9056\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3723 - siamese_loss: 4.5722 - mlp_loss: 0.3723 - mlp_binary_accuracy: 0.8320 - mlp_auc_65: 0.9126\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3701 - siamese_loss: 4.5309 - mlp_loss: 0.3701 - mlp_binary_accuracy: 0.8325 - mlp_auc_65: 0.9134\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4023 - siamese_loss: 3.6797 - mlp_loss: 0.4023 - mlp_binary_accuracy: 0.8345 - mlp_auc_65: 0.9070\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4495 - siamese_loss: 3.8910 - mlp_loss: 0.4495 - mlp_binary_accuracy: 0.7960 - mlp_auc_65: 0.8765\n",
      "验证集十折------ mlp_binary_accuracy: 83.45%\t ----- mlp_auc_65: 90.70% \n",
      "\n",
      "测试集------ mlp_binary_accuracy: 79.60%\t ----- mlp_auc_65: 87.65% \n",
      "\n",
      "训练集十折性能均值：-------- ave_acc: 79.46% (+/- 3.21%)\t ----- ave_auc_mlp:87.38% (+/- 2.56%)\n",
      "测试集性能均值：-------- ave_acc: 78.36% (+/- 1.83%)\t ----- ave_auc_mlp:86.72% (+/- 1.13%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.metrics  import roc_curve,auc,roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "cvacc,cvauc_mlp,cvpre,cvpre_top,cvrec,cvauc_sia=[],[],[],[],[],[]\n",
    "cvacc_test,cvauc_mlp_test,cvauc_sia_test=[],[],[]\n",
    "i =1\n",
    "\n",
    "\n",
    "neg_to_pos= 1\n",
    "rus = RandomUnderSampler(sampling_strategy=neg_to_pos,random_state=2) \n",
    "rus_dfmA,rus_y = rus.fit_resample(X=disA_fea_mat,y=y)\n",
    "rus_dfmB,rus_y = rus.fit_resample(X=disB_fea_mat,y=y)\n",
    "\n",
    "rus_mesh_A,rus_y = rus.fit_resample(X=mesh_label_A,y=y)\n",
    "rus_mesh_B,rus_y = rus.fit_resample(X=mesh_label_B,y=y)\n",
    "\n",
    "print('rus_y的长度:',len(rus_y))\n",
    "\n",
    "\"\"\"split 20%\"\"\"\n",
    "symA_train,symA_test,symB_train,symB_test,meshA_train,meshA_test,meshB_train,meshB_test,y_train,y_test=train_test_split(\n",
    "                rus_dfmA,rus_dfmB,\n",
    "                rus_mesh_A,rus_mesh_B,#mesh_label_A[-5515:-1],mesh_label_B[-5515:-1],\n",
    "                rus_y,\n",
    "                test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed) # This is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "python_random.seed(seed)# This is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "Kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "for train,test in Kfold.split(X=symA_train,y=y_train):\n",
    "    ###############################################################################################\n",
    "\n",
    "    input_shape=(385)\n",
    "    base_network = create_base_network(input_shape)\n",
    "    \n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "    input_mesh_a = Input(shape=24)\n",
    "    input_mesh_b = Input(shape=24)\n",
    "    \n",
    "\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "\n",
    "    eucl_model = create_euclLayer(processed_a.shape[-1])\n",
    "    eucl_out = eucl_model([processed_a,processed_b]) \n",
    "    \n",
    "\n",
    "    concat_fea = tf.keras.layers.concatenate([processed_a,input_mesh_a,processed_b,input_mesh_b],axis=-1)\n",
    "    print(\"concat_fea的shape：\",concat_fea.shape) #(None,32)\n",
    "    MLP = create_MLP(concat_fea.shape[-1])\n",
    "    MLP_out = MLP(concat_fea)\n",
    "    \n",
    "    model = Model(inputs=[input_a, input_b,input_mesh_a,input_mesh_b], outputs=[eucl_out,MLP_out])\n",
    "    \n",
    "    \"\"\"L2\"\"\"\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer,'kernel_regularizer'):\n",
    "            layer.kernel_regularizer = tf.keras.regularizers.l2(0.001)\n",
    "        \n",
    "    #####################################################################################################################\n",
    "\n",
    "    print(\"-------------------------------------Kfold: {} iter-----------------------------------------\".format(i))\n",
    "    i+=1\n",
    "\n",
    "    rms = RMSprop()\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=5)\n",
    "    \n",
    "    my_loss = {\"siamese\":contrastive_loss,\"mlp\":tf.keras.losses.BinaryCrossentropy()}\n",
    "    my_loss_weight = {\"siamese\":0,\"mlp\":1}\n",
    "    my_metrics ={ \"mlp\":[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()]} #tf.keras.metrics.Precision(top_k=len(rus_y)//100)\n",
    "    \n",
    "    model.compile(\n",
    "#         loss= [tfa.losses.ContrastiveLoss(),tf.keras.losses.BinaryCrossentropy()],\n",
    "#         loss_weights=[0.01,1],\n",
    "#         metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    "        \n",
    "        loss= my_loss,\n",
    "        loss_weights=my_loss_weight,\n",
    "        metrics=my_metrics,\n",
    "        \n",
    "        optimizer=rms,\n",
    "    )\n",
    "    \n",
    "    # fit()中 shuffle=True\n",
    "    model.fit([symA_train[train],symB_train[train],meshA_train[train],meshB_train[train]],\n",
    "              [y_train[train],y_train[train]],\n",
    "              \n",
    "              batch_size=None,\n",
    "              epochs=200,  #200-->50-->100\n",
    "              callbacks=callback,\n",
    "              shuffle=True,\n",
    "             )\n",
    "    \n",
    "#symA_train,symA_test,symB_train,symB_test,meshA_train,meshA_test,meshB_train,meshB_test,y_train,y_test    \n",
    "    valid_scores = model.evaluate([symA_train[test],symB_train[test],meshA_train[test],meshB_train[test]],\n",
    "                            [y_train[test],y_train[test]],\n",
    "                            verbose=1,\n",
    "                            batch_size=32)\n",
    "    \n",
    "    cvacc.append(valid_scores[-2] * 100)\n",
    "    cvauc_mlp.append(valid_scores[-1] * 100)\n",
    "    cvauc_sia.append(valid_scores[-3] * 100)\n",
    "    \n",
    "    test_scores = model.evaluate([symA_test,symB_test,meshA_test,meshB_test],\n",
    "                            [y_test,y_test],\n",
    "                            verbose=1,\n",
    "                            batch_size=32)\n",
    "    \n",
    "    cvacc_test.append(test_scores[-2] * 100)\n",
    "    cvauc_mlp_test.append(test_scores[-1] * 100)\n",
    "    cvauc_sia_test.append(test_scores[-3] * 100)\n",
    "    \n",
    "    print(\"验证集十折------ %s: %.2f%%\\t ----- %s: %.2f%% \\n\" % \n",
    "           (model.metrics_names[-2],valid_scores[-2]*100, model.metrics_names[-1],valid_scores[-1]*100))\n",
    "    print(\"测试集------ %s: %.2f%%\\t ----- %s: %.2f%% \\n\" % \n",
    "           (model.metrics_names[-2],test_scores[-2]*100, model.metrics_names[-1],test_scores[-1]*100))\n",
    "     \n",
    "print(\"训练集十折性能均值：-------- ave_acc: %.2f%% (+/- %.2f%%)\\t ----- ave_auc_mlp:%.2f%% (+/- %.2f%%)\" % \n",
    "      (np.mean(cvacc), np.std(cvacc),np.mean(cvauc_mlp), np.std(cvauc_mlp)))\n",
    "print(\"测试集性能均值：-------- ave_acc: %.2f%% (+/- %.2f%%)\\t ----- ave_auc_mlp:%.2f%% (+/- %.2f%%)\" % \n",
    "      (np.mean(cvacc_test), np.std(cvacc_test),np.mean(cvauc_mlp_test), np.std(cvauc_mlp_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ab0f4",
   "metadata": {},
   "source": [
    "####   resluts\n",
    "    1、10-fold avg：-------- ave_acc: 80.30% (+/- 2.14%)\t ----- ave_auc_mlp:87.53% (+/- 2.44%)\n",
    "    test avg：-------- ave_acc: 78.97% (+/- 1.52%)\t ----- ave_auc_mlp:87.12% (+/- 0.96%)\n",
    "    2、10-fold avg：-------- ave_acc: 79.46% (+/- 3.21%)\t ----- ave_auc_mlp:87.38% (+/- 2.56%)\n",
    "    test avg：-------- ave_acc: 78.36% (+/- 1.83%)\t ----- ave_auc_mlp:86.72% (+/- 1.13%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79b60689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4411\n",
      "1103\n",
      "4411\n",
      "1103\n",
      "4411\n",
      "1103\n"
     ]
    }
   ],
   "source": [
    "# symA_train,symA_test,symB_train,symB_test,meshA_train,meshA_test,meshB_train,meshB_test\n",
    "print(len(symA_train))\n",
    "print(len(symA_test))\n",
    "print(len(symB_train))\n",
    "print(len(symB_test))\n",
    "print(len(meshA_train))\n",
    "print(len(meshB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b9766",
   "metadata": {},
   "source": [
    "### using all data train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef506dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rus_y的长度: 5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'PYTHONHASHSEED' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_fea的shape： (None, 112)\n",
      "Epoch 1/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.6731 - siamese_loss: 3.7768 - mlp_loss: 0.6731 - mlp_binary_accuracy: 0.5805 - mlp_auc_66: 0.6140\n",
      "Epoch 2/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.6352 - siamese_loss: 3.1242 - mlp_loss: 0.6352 - mlp_binary_accuracy: 0.6467 - mlp_auc_66: 0.6891\n",
      "Epoch 3/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.6117 - siamese_loss: 2.9967 - mlp_loss: 0.6117 - mlp_binary_accuracy: 0.6656 - mlp_auc_66: 0.7221\n",
      "Epoch 4/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5923 - siamese_loss: 2.5803 - mlp_loss: 0.5923 - mlp_binary_accuracy: 0.6846 - mlp_auc_66: 0.7486\n",
      "Epoch 5/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5842 - siamese_loss: 2.8422 - mlp_loss: 0.5842 - mlp_binary_accuracy: 0.6922 - mlp_auc_66: 0.7583\n",
      "Epoch 6/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.5690 - siamese_loss: 3.1031 - mlp_loss: 0.5690 - mlp_binary_accuracy: 0.6922 - mlp_auc_66: 0.7751\n",
      "Epoch 7/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5416 - siamese_loss: 3.2172 - mlp_loss: 0.5416 - mlp_binary_accuracy: 0.7312 - mlp_auc_66: 0.8010\n",
      "Epoch 8/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5310 - siamese_loss: 3.2231 - mlp_loss: 0.5310 - mlp_binary_accuracy: 0.7392 - mlp_auc_66: 0.8119\n",
      "Epoch 9/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5144 - siamese_loss: 3.6458 - mlp_loss: 0.5144 - mlp_binary_accuracy: 0.7481 - mlp_auc_66: 0.8247\n",
      "Epoch 10/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5057 - siamese_loss: 4.0305 - mlp_loss: 0.5057 - mlp_binary_accuracy: 0.7543 - mlp_auc_66: 0.8316\n",
      "Epoch 11/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4915 - siamese_loss: 3.8180 - mlp_loss: 0.4915 - mlp_binary_accuracy: 0.7670 - mlp_auc_66: 0.8417\n",
      "Epoch 12/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4868 - siamese_loss: 3.0526 - mlp_loss: 0.4868 - mlp_binary_accuracy: 0.7684 - mlp_auc_66: 0.8449\n",
      "Epoch 13/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4780 - siamese_loss: 3.3779 - mlp_loss: 0.4780 - mlp_binary_accuracy: 0.7731 - mlp_auc_66: 0.8511\n",
      "Epoch 14/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4818 - siamese_loss: 3.5361 - mlp_loss: 0.4818 - mlp_binary_accuracy: 0.7717 - mlp_auc_66: 0.8493\n",
      "Epoch 15/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4741 - siamese_loss: 3.3505 - mlp_loss: 0.4741 - mlp_binary_accuracy: 0.7791 - mlp_auc_66: 0.8546\n",
      "Epoch 16/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4750 - siamese_loss: 2.8065 - mlp_loss: 0.4750 - mlp_binary_accuracy: 0.7708 - mlp_auc_66: 0.8536\n",
      "Epoch 17/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.4694 - siamese_loss: 2.4866 - mlp_loss: 0.4694 - mlp_binary_accuracy: 0.7793 - mlp_auc_66: 0.8569\n",
      "Epoch 18/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4604 - siamese_loss: 2.4372 - mlp_loss: 0.4604 - mlp_binary_accuracy: 0.7844 - mlp_auc_66: 0.8627\n",
      "Epoch 19/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.4506 - siamese_loss: 2.8779 - mlp_loss: 0.4506 - mlp_binary_accuracy: 0.7865 - mlp_auc_66: 0.8694\n",
      "Epoch 20/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4497 - siamese_loss: 3.2268 - mlp_loss: 0.4497 - mlp_binary_accuracy: 0.7952 - mlp_auc_66: 0.8695\n",
      "Epoch 21/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4482 - siamese_loss: 3.9613 - mlp_loss: 0.4482 - mlp_binary_accuracy: 0.7882 - mlp_auc_66: 0.8710\n",
      "Epoch 22/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4458 - siamese_loss: 4.4130 - mlp_loss: 0.4458 - mlp_binary_accuracy: 0.7949 - mlp_auc_66: 0.8714\n",
      "Epoch 23/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4372 - siamese_loss: 4.6211 - mlp_loss: 0.4372 - mlp_binary_accuracy: 0.7987 - mlp_auc_66: 0.8775\n",
      "Epoch 24/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4327 - siamese_loss: 4.5936 - mlp_loss: 0.4327 - mlp_binary_accuracy: 0.8027 - mlp_auc_66: 0.8807\n",
      "Epoch 25/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4245 - siamese_loss: 4.5508 - mlp_loss: 0.4245 - mlp_binary_accuracy: 0.8040 - mlp_auc_66: 0.8848\n",
      "Epoch 26/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4260 - siamese_loss: 4.4012 - mlp_loss: 0.4260 - mlp_binary_accuracy: 0.8032 - mlp_auc_66: 0.8846\n",
      "Epoch 27/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.4259 - siamese_loss: 4.7350 - mlp_loss: 0.4259 - mlp_binary_accuracy: 0.8059 - mlp_auc_66: 0.8842\n",
      "Epoch 28/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4136 - siamese_loss: 4.5478 - mlp_loss: 0.4136 - mlp_binary_accuracy: 0.8112 - mlp_auc_66: 0.8907\n",
      "Epoch 29/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4148 - siamese_loss: 4.4310 - mlp_loss: 0.4148 - mlp_binary_accuracy: 0.8079 - mlp_auc_66: 0.8898\n",
      "Epoch 30/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4092 - siamese_loss: 4.4667 - mlp_loss: 0.4092 - mlp_binary_accuracy: 0.8128 - mlp_auc_66: 0.8928\n",
      "Epoch 31/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.4166 - siamese_loss: 4.2786 - mlp_loss: 0.4166 - mlp_binary_accuracy: 0.8132 - mlp_auc_66: 0.8902\n",
      "Epoch 32/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4115 - siamese_loss: 4.3410 - mlp_loss: 0.4115 - mlp_binary_accuracy: 0.8085 - mlp_auc_66: 0.8921\n",
      "Epoch 33/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4097 - siamese_loss: 4.2990 - mlp_loss: 0.4097 - mlp_binary_accuracy: 0.8110 - mlp_auc_66: 0.8932\n",
      "Epoch 34/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4026 - siamese_loss: 4.0284 - mlp_loss: 0.4026 - mlp_binary_accuracy: 0.8177 - mlp_auc_66: 0.8970\n",
      "Epoch 35/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4075 - siamese_loss: 4.3010 - mlp_loss: 0.4075 - mlp_binary_accuracy: 0.8137 - mlp_auc_66: 0.8948\n",
      "Epoch 36/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.4010 - siamese_loss: 4.0701 - mlp_loss: 0.4010 - mlp_binary_accuracy: 0.8174 - mlp_auc_66: 0.8972\n",
      "Epoch 37/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3996 - siamese_loss: 4.0948 - mlp_loss: 0.3996 - mlp_binary_accuracy: 0.8188 - mlp_auc_66: 0.8988\n",
      "Epoch 38/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3859 - siamese_loss: 4.0855 - mlp_loss: 0.3859 - mlp_binary_accuracy: 0.8293 - mlp_auc_66: 0.9048\n",
      "Epoch 39/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3891 - siamese_loss: 4.3103 - mlp_loss: 0.3891 - mlp_binary_accuracy: 0.8232 - mlp_auc_66: 0.9040\n",
      "Epoch 40/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3986 - siamese_loss: 4.3751 - mlp_loss: 0.3986 - mlp_binary_accuracy: 0.8194 - mlp_auc_66: 0.8992\n",
      "Epoch 41/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3869 - siamese_loss: 4.1755 - mlp_loss: 0.3869 - mlp_binary_accuracy: 0.8196 - mlp_auc_66: 0.9046\n",
      "Epoch 42/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3836 - siamese_loss: 4.2058 - mlp_loss: 0.3836 - mlp_binary_accuracy: 0.8270 - mlp_auc_66: 0.9070\n",
      "Epoch 43/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3837 - siamese_loss: 4.2086 - mlp_loss: 0.3837 - mlp_binary_accuracy: 0.8264 - mlp_auc_66: 0.9066\n",
      "Epoch 44/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3751 - siamese_loss: 4.4092 - mlp_loss: 0.3751 - mlp_binary_accuracy: 0.8301 - mlp_auc_66: 0.9103\n",
      "Epoch 45/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3764 - siamese_loss: 4.4614 - mlp_loss: 0.3764 - mlp_binary_accuracy: 0.8288 - mlp_auc_66: 0.9093\n",
      "Epoch 46/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3735 - siamese_loss: 4.6617 - mlp_loss: 0.3735 - mlp_binary_accuracy: 0.8341 - mlp_auc_66: 0.9110\n",
      "Epoch 47/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3728 - siamese_loss: 4.5549 - mlp_loss: 0.3728 - mlp_binary_accuracy: 0.8361 - mlp_auc_66: 0.9119\n",
      "Epoch 48/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3729 - siamese_loss: 4.4736 - mlp_loss: 0.3729 - mlp_binary_accuracy: 0.8319 - mlp_auc_66: 0.9112\n",
      "Epoch 49/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3684 - siamese_loss: 4.4773 - mlp_loss: 0.3684 - mlp_binary_accuracy: 0.8337 - mlp_auc_66: 0.9136\n",
      "Epoch 50/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3759 - siamese_loss: 4.6477 - mlp_loss: 0.3759 - mlp_binary_accuracy: 0.8308 - mlp_auc_66: 0.9098\n",
      "Epoch 51/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3618 - siamese_loss: 4.7259 - mlp_loss: 0.3618 - mlp_binary_accuracy: 0.8399 - mlp_auc_66: 0.9173\n",
      "Epoch 52/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3642 - siamese_loss: 4.7473 - mlp_loss: 0.3642 - mlp_binary_accuracy: 0.8344 - mlp_auc_66: 0.9153\n",
      "Epoch 53/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3704 - siamese_loss: 4.8228 - mlp_loss: 0.3704 - mlp_binary_accuracy: 0.8315 - mlp_auc_66: 0.9131\n",
      "Epoch 54/200\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3624 - siamese_loss: 5.0754 - mlp_loss: 0.3624 - mlp_binary_accuracy: 0.8357 - mlp_auc_66: 0.9162\n",
      "Epoch 55/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3680 - siamese_loss: 5.0386 - mlp_loss: 0.3680 - mlp_binary_accuracy: 0.8357 - mlp_auc_66: 0.9148\n",
      "Epoch 56/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3581 - siamese_loss: 4.7821 - mlp_loss: 0.3581 - mlp_binary_accuracy: 0.8362 - mlp_auc_66: 0.9180\n",
      "Epoch 57/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3648 - siamese_loss: 5.0669 - mlp_loss: 0.3648 - mlp_binary_accuracy: 0.8397 - mlp_auc_66: 0.9161\n",
      "Epoch 58/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3643 - siamese_loss: 5.1709 - mlp_loss: 0.3643 - mlp_binary_accuracy: 0.8388 - mlp_auc_66: 0.9162\n",
      "Epoch 59/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3656 - siamese_loss: 5.2113 - mlp_loss: 0.3656 - mlp_binary_accuracy: 0.8368 - mlp_auc_66: 0.9157\n",
      "Epoch 60/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3529 - siamese_loss: 5.1449 - mlp_loss: 0.3529 - mlp_binary_accuracy: 0.8429 - mlp_auc_66: 0.9209\n",
      "Epoch 61/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3462 - siamese_loss: 5.2245 - mlp_loss: 0.3462 - mlp_binary_accuracy: 0.8429 - mlp_auc_66: 0.9243\n",
      "Epoch 62/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3448 - siamese_loss: 5.3739 - mlp_loss: 0.3448 - mlp_binary_accuracy: 0.8497 - mlp_auc_66: 0.9253\n",
      "Epoch 63/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3526 - siamese_loss: 5.2498 - mlp_loss: 0.3526 - mlp_binary_accuracy: 0.8348 - mlp_auc_66: 0.9211\n",
      "Epoch 64/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3568 - siamese_loss: 5.2135 - mlp_loss: 0.3568 - mlp_binary_accuracy: 0.8391 - mlp_auc_66: 0.9195\n",
      "Epoch 65/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3468 - siamese_loss: 5.1050 - mlp_loss: 0.3468 - mlp_binary_accuracy: 0.8462 - mlp_auc_66: 0.9237\n",
      "Epoch 66/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3432 - siamese_loss: 5.2290 - mlp_loss: 0.3432 - mlp_binary_accuracy: 0.8460 - mlp_auc_66: 0.9255\n",
      "Epoch 67/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3472 - siamese_loss: 5.2522 - mlp_loss: 0.3472 - mlp_binary_accuracy: 0.8464 - mlp_auc_66: 0.9235\n",
      "Epoch 68/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3614 - siamese_loss: 4.7573 - mlp_loss: 0.3614 - mlp_binary_accuracy: 0.8341 - mlp_auc_66: 0.9165\n",
      "Epoch 69/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3569 - siamese_loss: 4.6244 - mlp_loss: 0.3569 - mlp_binary_accuracy: 0.8440 - mlp_auc_66: 0.9198\n",
      "Epoch 70/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3510 - siamese_loss: 4.5238 - mlp_loss: 0.3510 - mlp_binary_accuracy: 0.8366 - mlp_auc_66: 0.9213\n",
      "Epoch 71/200\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.3494 - siamese_loss: 4.6966 - mlp_loss: 0.3494 - mlp_binary_accuracy: 0.8415 - mlp_auc_66: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x263144ee7c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.metrics  import roc_curve,auc,roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "cvacc,cvauc_mlp,cvpre,cvpre_top,cvrec,cvauc_sia=[],[],[],[],[],[]\n",
    "cvacc_test,cvauc_mlp_test,cvauc_sia_test=[],[],[]\n",
    "i =1\n",
    "\n",
    "\n",
    "neg_to_pos= 1\n",
    "rus = RandomUnderSampler(sampling_strategy=neg_to_pos,random_state=2) \n",
    "rus_dfmA,rus_y = rus.fit_resample(X=disA_fea_mat,y=y)\n",
    "rus_dfmB,rus_y = rus.fit_resample(X=disB_fea_mat,y=y)\n",
    "\n",
    "rus_mesh_A,rus_y = rus.fit_resample(X=mesh_label_A,y=y)\n",
    "rus_mesh_B,rus_y = rus.fit_resample(X=mesh_label_B,y=y)\n",
    "\n",
    "print('rus_y的长度:',len(rus_y))\n",
    "\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed) # This is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "python_random.seed(seed)# This is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "input_shape=(385)\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "input_mesh_a = Input(shape=24)\n",
    "input_mesh_b = Input(shape=24)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "eucl_model = create_euclLayer(processed_a.shape[-1])\n",
    "eucl_out = eucl_model([processed_a,processed_b]) \n",
    "\n",
    "\n",
    "concat_fea = tf.keras.layers.concatenate([processed_a,input_mesh_a,processed_b,input_mesh_b],axis=-1)\n",
    "print(\"concat_fea的shape：\",concat_fea.shape) #(None,32)\n",
    "MLP = create_MLP(concat_fea.shape[-1])\n",
    "MLP_out = MLP(concat_fea)\n",
    "\n",
    "model = Model(inputs=[input_a, input_b,input_mesh_a,input_mesh_b], outputs=[eucl_out,MLP_out])\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer,'kernel_regularizer'):\n",
    "        layer.kernel_regularizer = tf.keras.regularizers.l2(0.001)\n",
    "    \n",
    "#####################################################################################################################\n",
    "\n",
    "rms = RMSprop()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=5)\n",
    "\n",
    "my_loss = {\"siamese\":contrastive_loss,\"mlp\":tf.keras.losses.BinaryCrossentropy()}\n",
    "my_loss_weight = {\"siamese\":0,\"mlp\":1}\n",
    "my_metrics ={ \"mlp\":[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()]} #tf.keras.metrics.Precision(top_k=len(rus_y)//100)\n",
    "\n",
    "model.compile(\n",
    "#         loss= [tfa.losses.ContrastiveLoss(),tf.keras.losses.BinaryCrossentropy()],\n",
    "#         loss_weights=[0.01,1],\n",
    "#         metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    "        \n",
    "    loss= my_loss,\n",
    "    loss_weights=my_loss_weight,\n",
    "    metrics=my_metrics,\n",
    "    \n",
    "    optimizer=rms,\n",
    ")\n",
    "\n",
    "# fit()中 shuffle=True\n",
    "model.fit([rus_dfmA,rus_dfmB,rus_mesh_A,rus_mesh_B],\n",
    "          [rus_y,rus_y],\n",
    "          \n",
    "          batch_size=None,\n",
    "          epochs=200,  #200-->50-->100\n",
    "          callbacks=callback,\n",
    "          shuffle=True,\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff61a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"Undersampling_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbfc4f",
   "metadata": {},
   "source": [
    "### predict 42195 disease pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cebc0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "predict_result = model.predict([disA_fea_mat,disB_fea_mat,mesh_label_A,mesh_label_B])\n",
    "print(len(predict_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0caaee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42195\n",
      "42195\n",
      "[[5.       ]\n",
      " [4.898979 ]\n",
      " [3.8729832]\n",
      " ...\n",
      " [1.7320508]\n",
      " [4.8989797]\n",
      " [5.       ]]\n",
      "[[2.6254924e-05]\n",
      " [1.3631827e-01]\n",
      " [4.7320038e-02]\n",
      " ...\n",
      " [1.1805803e-02]\n",
      " [5.6417070e-07]\n",
      " [1.9087295e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_result[0]))\n",
    "print(len(predict_result[1]))\n",
    "print(predict_result[0])\n",
    "print(predict_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2268c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(predict_result[1],columns=[\"predict_score\"]).to_csv(\"model_predict42195_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c4f7c",
   "metadata": {},
   "source": [
    "### predict disease pair similarities of 4268 diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ebf43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pediatric Obesity</th>\n",
       "      <th>Orthostatic Intolerance</th>\n",
       "      <th>Seizures</th>\n",
       "      <th>Muscle Weakness</th>\n",
       "      <th>Persistent Vegetative State</th>\n",
       "      <th>Chills</th>\n",
       "      <th>Sweating Sickness</th>\n",
       "      <th>Ataxia</th>\n",
       "      <th>Nocturia</th>\n",
       "      <th>Fetal Distress</th>\n",
       "      <th>...</th>\n",
       "      <th>Hypercalciuria</th>\n",
       "      <th>Chronic Pain</th>\n",
       "      <th>Hematemesis</th>\n",
       "      <th>Angina Pectoris</th>\n",
       "      <th>Vision, Low</th>\n",
       "      <th>Muscle Hypertonia</th>\n",
       "      <th>Hearing Loss, Functional</th>\n",
       "      <th>Breakthrough Pain</th>\n",
       "      <th>Mutism</th>\n",
       "      <th>Cerebrospinal Fluid Otorrhea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nevus, Intradermal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superinfection</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.309646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pediatric Obesity  Orthostatic Intolerance  Seizures  \\\n",
       "Nevus, Intradermal                0.0                      0.0       0.0   \n",
       "Superinfection                    0.0                      0.0       0.0   \n",
       "\n",
       "                    Muscle Weakness  Persistent Vegetative State  Chills  \\\n",
       "Nevus, Intradermal         0.000000                          0.0     0.0   \n",
       "Superinfection             0.635781                          0.0     0.0   \n",
       "\n",
       "                    Sweating Sickness  Ataxia  Nocturia  Fetal Distress  ...  \\\n",
       "Nevus, Intradermal                0.0     0.0       0.0             0.0  ...   \n",
       "Superinfection                    0.0     0.0       0.0             0.0  ...   \n",
       "\n",
       "                    Hypercalciuria  Chronic Pain  Hematemesis  \\\n",
       "Nevus, Intradermal             0.0      0.000000          0.0   \n",
       "Superinfection                 0.0      1.309646          0.0   \n",
       "\n",
       "                    Angina Pectoris  Vision, Low  Muscle Hypertonia  \\\n",
       "Nevus, Intradermal              0.0          0.0                0.0   \n",
       "Superinfection                  0.0          0.0                0.0   \n",
       "\n",
       "                    Hearing Loss, Functional  Breakthrough Pain  Mutism  \\\n",
       "Nevus, Intradermal                       0.0                0.0     0.0   \n",
       "Superinfection                           0.0                0.0     0.0   \n",
       "\n",
       "                    Cerebrospinal Fluid Otorrhea  \n",
       "Nevus, Intradermal                           0.0  \n",
       "Superinfection                               0.0  \n",
       "\n",
       "[2 rows x 385 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_sym_fea = pd.read_csv(\"../../python爬虫/2020_TF-IDF_dropdup.csv\",index_col=0)\n",
    "dis_sym_fea[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "964a231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mesothelioma, cystic</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palatal neoplasms</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0  1  2  3  4  5  6  7  8  9  ...  14  15  16  17  18  \\\n",
       "mesothelioma, cystic  0  1  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   \n",
       "palatal neoplasms     0  1  1  0  1  0  0  0  0  0  ...   0   0   0   0   0   \n",
       "\n",
       "                      19  20  21  22  23  \n",
       "mesothelioma, cystic   0   0   0   0   0  \n",
       "palatal neoplasms      0   0   0   0   0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_mesh_fea = pd.read_csv(\"Mesh_files/label_array_new.csv\",index_col=0)\n",
    "dis_mesh_fea[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9c26ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                            | 86/4268 [02:46<2:14:49,  1.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-51065625c032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdisA\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_sym_fea\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdisB\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdis_sym_fea\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msymA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_sym_fea\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdisA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0msymB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_sym_fea\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdisB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "symA=[]\n",
    "symB=[]\n",
    "meshA=[]\n",
    "meshB=[]\n",
    "\n",
    "for disA in tqdm(dis_sym_fea.index):\n",
    "    for disB in dis_sym_fea.index:\n",
    "        symA.append(dis_sym_fea.loc[disA])\n",
    "        symB.append(dis_sym_fea.loc[disB])\n",
    "        \n",
    "        meshA.append(dis_mesh_fea.loc[disA.lower()])\n",
    "        meshB.append(dis_mesh_fea.loc[disB.lower()])\n",
    "        \n",
    "pd.DataFrame(symA).to_csv(\"all_symA.csv\")\n",
    "pd.DataFrame(symB).to_csv(\"all_symB.csv\")\n",
    "pd.DataFrame(meshA).to_csv(\"all_meshA.csv\")\n",
    "pd.DataFrame(meshB).to_csv(\"all_meshB.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
